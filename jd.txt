1. J.U.C

   1.1 多线程的实现方式？

   > 答：
   >
   > 1.继承Thread类，重写run方法
   >
   > 2.实现Runnable接口,重写run方法
   >
   > 3.实现Callable接口,重写call方法,可提供返回值
   >
   > 4.线程池：提供了一个线程队列，队列中保存着所有等待状态的线程。避免了创建与销毁额外开销，提高了响应的速度。

   1.2 CountDownLatch

   > **答：**
   >
   > CyclicBarrier和CountDownLatch 都位于java.util.concurrent 这个包下。
   >
   > | **CountDownLatch**                                           | **CyclicBarrier**                                            |
   > | ------------------------------------------------------------ | ------------------------------------------------------------ |
   > | **减计数方式**                                               | **加计数方式**                                               |
   > | **计算为0时释放所有等待的线程**                              | **计数达到指定值时释放所有等待线程**                         |
   > | **计数为0时，无法重置**                                      | **计数达到指定值时，计数置为0重新开始**                      |
   > | **调用countDown()方法计数减一，调用await()方法只进行阻塞，对计数没任何影响** | **调用await()方法计数加1，若加1后的值不等于构造方法的值，则线程阻塞** |
   > | **不可重复利用**                                             | **可重复利用**                                               |

   1.3 volatile

   > 答：
   >
   > 作用：常用于保持内存可见性和防止指令重排序。
   >
   > **Java8种原子操作：**
   >
   > Java通过几种原子操作完成工作内存和主内存的交互：
   >
   > lock：作用于主内存，把变量标识为线程独占状态。
   >
   > unlock：作用于主内存，解除独占状态。
   >
   > read：作用主内存，把一个变量的值从主内存传输到线程的工作内存。
   >
   > load：作用于工作内存，把read操作传过来的变量值放入工作内存的变量副本中。
   >
   > use：作用工作内存，把工作内存当中的一个变量值传给执行引擎。
   >
   > assign：作用工作内存，把一个从执行引擎接收到的值赋值给工作内存的变量。
   >
   > store：作用于工作内存的变量，把工作内存的一个变量的值传送到主内存中。
   >
   > write：作用于主内存的变量，把store操作传来的变量的值放入主内存的变量中。
   >
   > volatile如何保持内存可见性
   >
   > volatile的特殊规则就是：
   >
   > read、load、use动作必须连续出现。
   >
   > assign、store、write动作必须连续出现。
   >
   > 所以，使用volatile变量能够保证:
   >
   > 每次读取前必须先从主内存刷新最新的值。
   >
   > 每次写入后必须立即同步回主内存当中。
   >
   > 也就是说，volatile关键字修饰的变量看到的随时是自己的最新值。线程1中对变量v的最新修改，对线程2是可见的。
   >
   > 防止指令重排
   >
   > 在基于偏序关系的Happens-Before内存模型中，指令重排技术大大提高了程序执行效率，但同时也引入了一些问题。
   >
   > 一个指令重排的问题——被部分初始化的对象
   >
   > **懒加载单例模式和竞态条件**
   >
   > 一个懒加载的单例模式实现如下：
   >
   > ```java
   > class Singleton{
   > 	private static Singleton instance;
   > 	private Singleton(){}
   > 	public static Singleton getInstance(){
   > 		if(instance == null){ //这里存在竞态条件
   > 			instance = new Singleton();
   > 		}
   > 		return instance;
   > 	}
   > }
   > ```
   >
   > 竞态条件会导致instance引用被多次赋值，使用户得到两个不同的单例。
   >
   > 为了解决这个问题，可以使用synchronized关键字将getInstance方法改为同步方法；但这样串行化的单例是不能忍的。所以设计了DCL（Double Check Lock，双重检查锁）机制，使得大部分请求都不会进入阻塞代码块：
   >
   > ```java
   > class Singleton{
   > 	private static Singleton instance;
   > 	private Singleton(){}
   > 	public static Singleton getInstance(){
   > 		if(instance == null){ //当instance不为null时，仍然可能指向一个被“部分初始化”的对象
   > 			synchronized（Singleton.class）{
   > 				if(instance == null){
   > 					instance = new Singleton();
   > 				}
   > 			}
   > 		}
   > 		return instance;
   > 	}
   > }
   > ```
   >
   > “看起来”非常完美：既减少了阻塞，又避免了竞态条件。不错，但实际上仍然存在一个问题——当instance不为null时，仍可能指向一个"被部分初始化的对象"
   >
   > 以A、B两个线程为例：
   >
   > A、B线程同时进入了第一个if判断
   >
   > A首先进入synchronized块，由于instance为null，所以它执行instance = new Singleton();
   >
   > 由于JVM内部的优化机制，JVM先画出了一些分配给Singleton实例的空白内存，并赋值给instance成员（注意此时JVM没有开始初始化这个实例），然后A离开了synchronized块。
   >
   > B进入synchronized块，由于instance此时不是null，因此它马上离开了synchronized块并将结果返回给调用该方法的程序。
   >
   > 此时B线程打算使用Singleton实例，却发现它没有被初始化，于是错误发生了。
   >
   > 解决这个该问题，只需要将instance声明为volatile变量：
   >
   > private static volatile Singleton instance;
   >
   > 或者
   >
   > ```java
   > class Singleton{
   > 	private static Singleton instance;
   > 	private Singleton(){
   >     ……
   >   }
   > 	public static class SingletonContainer(){
   >     private static Singleton instance = new Songleton();
   >   }
   > 	public static Singleton getInstance(){
   >     return SingletonContainer.instance;
   >   }	
   >   
   > }
   > ```
   >
   > JVM内部的机制能够保证当一个类被加载的时候，这个类的加载过程是线程互斥的。这样当我们第一次调用getInstance的时候，JVM能够帮我们保证instance只被创建一次，并且会保证把赋值给instance的内存初始化完毕。此外该方法也只会在第一次调用的时候使用互斥机制，这样就解决了低效问题。最后instance是在第一次加载SingletonContainer类时被创建的，而SingletonContainer类则在调用getInstance方法的时候才会被加载，因此也实现了惰性加载。

   1.4 锁重入(Synchronized 和 ReentrantLock的区别？)

   > 答：
   >
   > 可重入锁：可重入锁是指同一个线程可以多次获取同一把锁。ReentrantLock和synchronized都是可重入锁。
   >
   > 可中断锁：可中断锁是指线程尝试获取锁的过程中，是否可以响应中断。Synchronized是不可中断锁，而ReentrantLock则提供了中断功能。
   >
   > 公平锁与非公平锁：公平锁是指多个线程同时尝试获取同一把锁时，获取锁的顺序按照线程达到的顺序，而非公平锁则允许线程“插队”。Synchronized是非公平锁，而ReentrantLock的默认实现是非公平锁，但是也可以设置为公平锁。
   >
   > CAS操作(CompareAndSwap)：CAS操作简单的说就是比较并交换。CAS 操作包含三个操作数 —— 内存位置（V）、预期原值（A）和新值(B)。如果内存位置的值与预期原值相匹配，那么处理器会自动将该位置值更新为新值。否则，处理器不做任何操作。无论哪种情况，它都会在 CAS 指令之前返回该位置的值。CAS 有效地说明了“我认为位置 V 应该包含值 A；如果包含该值，则将 B 放到这个位置；否则，不要更改该位置，只告诉我这个位置现在的值即可。”
   >
   > **Synchronized**
   >
   > Synchronized是java内置的关键字，它提供了一种独占的加锁方式。Synchronized的获取和释放锁由JVM实现，用户不需要显示的释放锁，非常方便。然而Synchronized也有一定的局限性
   >
   > 例如：
   >
   > 当线程尝试获取锁的时候，如果获取不到锁会一直阻塞。
   >
   > 如果获取锁的线程进入休眠或者阻塞，除非当前线程异常，否则其他线程尝试获取锁必须一直等待。
   >
   > **ReentrantLock**
   >
   > ReentrantLock它是JDK 1.5之后提供的API层面的互斥锁，需要lock()和unlock()方法配合try/finally语句块来完成。
   >
   > ```java
   > private Lock lock = new ReentranLock();
   > public void test(){
   >   lock.lock();
   >   try{
   >     doSomeThing();
   >   }catch(Exception e){
   >     //ignored
   >   }finally{
   >     lock.unlock();
   >   }
   > }
   > //lock(), 如果获取了锁立即返回，如果别的线程持有锁，当前线程则一直处于休眠状态，直到获取锁
   > //tryLock(), 如果获取了锁立即返回true，如果别的线程正持有锁，立即返回false；
   > //tryLock(long timeout,TimeUnit unit)，如果获取了锁定立即返回true，如果别的线程正持有锁，会等待参数给定的时间，在等待的过程中，如果获取了锁定，就返回true，如果等待超时，返回false；
   > //lockInterruptibly:如果获取了锁定立即返回，如果没有获取锁定，当前线程处于休眠状态，直到或者锁定，或者当前线程被别的线程中断
   > ```
   >
   > **ReentrantLock 一些特性**
   >
   > 等待可中断避免，出现死锁的情况（如果别的线程正持有锁，会等待参数给定的时间，在等待的过程中，如果获取了锁定，就返回true，如果等待超时，返回false）
   >
   > 公平锁与非公平锁多个线程等待同一个锁时，必须按照申请锁的时间顺序获得锁，Synchronized锁非公平锁，ReentrantLock默认的构造函数是创建的非公平锁，可以通过参数true设为公平锁，但公平锁表现的性能不是很好。
   >
   > 公平锁：线程获取锁的顺序和调用lock的顺序一样，FIFO；
   >
   > 非公平锁：线程获取锁的顺序和调用lock的顺序无关，全凭运气。
   >
   > Java并发包(java.util.concurrent)中大量使用了CAS操作,涉及到并发的地方都调用了sun.misc.Unsafe类方法进行CAS操作。
   >
   > **ReenTrantLock实现的原理：**
   >
   > 简单来说，ReenTrantLock的实现是一种自旋锁，通过循环调用CAS操作来实现加锁。它的性能比较好也是因为避免了使线程进入内核态的阻塞状态。想尽办法避免线程进入内核的阻塞状态是我们去分析和理解锁设计的关键钥匙。
   >
   > **总结一下**
   >
   > 在Synchronized优化以前，synchronized的性能是比ReenTrantLock差很多的，但是自从Synchronized引入了偏向锁，轻量级锁（自旋锁）后，两者的性能就差不多了，在两种方法都可用的情况下，官方甚至建议使用synchronized，其实synchronized的优化我感觉就借鉴了ReenTrantLock中的CAS技术。都是试图在用户态就把加锁问题解决，避免进入内核态的线程阻塞。
   >
   > synchronized：
   >
   > 在资源竞争不是很激烈的情况下，偶尔会有同步的情形下，synchronized是很合适的。原因在于，编译程序通常会尽可能的进行优化synchronize，另外可读性非常好。
   >
   > ReentrantLock:
   >
   > ReentrantLock用起来会复杂一些。在基本的加锁和解锁上，两者是一样的，所以无特殊情况下，推荐使用synchronized。ReentrantLock的优势在于它更灵活、更强大，增加了轮训、超时、中断等高级功能。
   >
   > ReentrantLock默认使用非公平锁是基于性能考虑，公平锁为了保证线程规规矩矩地排队，需要增加阻塞和唤醒的时间开销。如果直接插队获取非公平锁，跳过了对队列的处理，速度会更快。

   1.5 LinkedTransferQueue 字节追加提高并发度

   1.6 ConcurrentHashMap结合volatile的happen-before读取优化

   > 答：
   >
   > 我们无法就所有场景来规定某个线程修改的变量何时对其他线程可见，但是我们可以指定某些规则，这规则就是happens-before。特别关注在多线程之间的内存可见性。
   >
   > 它是判断数据是否存在竞争、线程是否安全的主要依据，依靠这个原则，我们解决在并发环境下两操作之间是否可能存在冲突的所有问题。
   >
   > 程序次序规则：一个线程内，按照代码顺序，书写在前面的操作先行发生于书写在后面的操作；
   > 锁定规则：一个unLock操作先行发生于后面对同一个锁额lock操作；
   > volatile变量规则：对一个变量的写操作先行发生于后面对这个变量的读操作；
   > 传递规则：如果操作A先行发生于操作B，而操作B又先行发生于操作C，则可以得出操作A先行发生于操作C；
   > 线程启动规则：Thread对象的start()方法先行发生于此线程的每个一个动作；
   > 线程中断规则：对线程interrupt()方法的调用先行发生于被中断线程的代码检测到中断事件的发生；
   > 线程终结规则：线程中所有的操作都先行发生于线程的终止检测，我们可以通过Thread.join()方法结束、Thread.isAlive()的返回值手段检测到线程已经终止执行；
   > 对象终结规则：一个对象的初始化完成先行发生于他的finalize()方法的开始；

   1.7 线程池原理？种类？线程池工厂的线程池类型？线程池参数？

   > 答：
   >
   > **为什么要用线程池:**
   >
   > 减少了创建和销毁线程的次数，每个工作线程都可以被重复利用，可执行多个任务。
   >
   >  
   >
   > 可以根据系统的承受能力，调整线程池中工作线线程的数目，防止因为消耗过多的内存，而把服务器累趴下(每个线程需要大约1MB内存，线程开的越多，消耗的内存也就越大，最后死机)。
   >
   > Java里面线程池的顶级接口是Executor，但是严格意义上讲Executor并不是一个线程池，而只是一个执行线程的工具。真正的线程池接口是ExecutorService。
   >
   > **new Thread 缺点**
   >
   > 每次new Thread新建对象性能差。
   >
   > 线程缺乏统一管理，可能无限制新建线程，相互之间竞争，及可能占用过多系统资源导致死机或oom。
   >
   > 缺乏更多功能，如定时执行、定期执行、线程中断。
   >
   > **ThreadPool 优点**
   >
   > 减少了创建和销毁线程的次数，每个工作线程都可以被重复利用，可执行多个任务
   >
   > 可以根据系统的承受能力，调整线程池中工作线线程的数目，防止因为因为消耗过多的内存，而把服务器累趴下(每个线程需要大约1MB内存，线程开的越多，消耗的内存也就越大，最后死机)
   >
   > 减少在创建和销毁线程上所花的时间以及系统资源的开销
   >
   > 如不使用线程池，有可能造成系统创建大量线程而导致消耗完系统内存
   >
   > **Java提供的四种线程池的好处在于：**
   >
   > 重用存在的线程，减少对象创建、销毁的开销，提高性能。
   >
   > 可有效控制最大并发线程数，提高系统资源的使用率，同时避免过多资源竞争，避免堵塞。
   >
   > 提供定时执行、定期执行、单线程、并发数控制等功能。
   >
   > 比较重要的几个类：
   >
   > | 类                          | 描述                                                         |
   > | --------------------------- | ------------------------------------------------------------ |
   > | ExecutorService             | 真正的线程池接口。                                           |
   > | ScheduledExecutorService    | 能和Timer/TimerTask类似，解决那些需要任务重复执行的问题。    |
   > | ThreadPoolExecutor          | ExecutorService的默认实现。                                  |
   > | ScheduledThreadPoolExecutor | 继承ThreadPoolExecutor的ScheduledExecutorService接口实现，周期性任务调度的类实现。 |
   >
   > 要配置一个线程池是比较复杂的，尤其是对于线程池的原理不是很清楚的情况下，很有可能配置的线程池不是较优的，因此在Executors类里面提供了一些静态工厂，生成一些常用的线程池。
   >
   > **Executors提供四种线程池**
   >
   > newCachedThreadPool创建一个可缓存线程池，如果线程池长度超过处理需要，可灵活回收空闲线程，若无可回收，则新建线程。
   >
   > newFixedThreadPool 创建一个定长线程池，可控制线程最大并发数，超出的线程会在队列中等待。
   >
   > newScheduledThreadPool 创建一个定长线程池，支持定时及周期性任务执行。
   >
   > newSingleThreadExecutor 创建一个单线程化的线程池，它只会用唯一的工作线程来执行任务，保证所有任务按照指定顺序(FIFO, LIFO, 优先级)执行。
   >
   > 一般都不用Executors提供的线程创建方式
   >
   > 使用ThreadPoolExecutor创建线程池，ThreadPoolExecutor的构造函数
   >
   > **参数：**
   >
   > corePoolSize核心线程数大小，当线程数<corepoolsize ，会创建线程执行runnable<="" li="" style="box-sizing: border-box;">
   >
   > maximumPoolSize 最大线程数，当线程数 >= corePoolSize的时候，会把runnable放入workQueue中
   >
   > keepAliveTime 保持存活时间，当线程数大于corePoolSize的空闲线程能保持的最大时间。
   >
   > unit 时间单位
   >
   > workQueue 保存任务的阻塞队列
   >
   > threadFactory 创建线程的工厂
   >
   > handler 拒绝策略
   >
   > **任务执行顺序：**
   >
   > 当线程数小于corePoolSize时，创建线程执行任务。
   >
   > 当线程数大于等于corePoolSize并且workQueue没有满时，放入workQueue中
   >
   > 线程数大于等于corePoolSize并且当workQueue满时，新任务新建线程运行，线程总数要小于maximumPoolSize
   >
   > 当线程总数等于maximumPoolSize并且workQueue满了的时候执行handler的rejectedExecution。也就是拒绝策略。
   >
   > **ThreadPoolExecutor默认有四个拒绝策略：**
   >
   > ThreadPoolExecutor.AbortPolicy() 直接抛出异常RejectedExecutionException
   >
   > ThreadPoolExecutor.CallerRunsPolicy() 直接调用run方法并且阻塞执行
   >
   > ThreadPoolExecutor.DiscardPolicy() 直接丢弃后来的任务
   >
   > ThreadPoolExecutor.DiscardOldestPolicy() 丢弃在队列中队首的任务
   >
   > 当然可以自己继承RejectedExecutionHandler 来写拒绝策略.

   1.8 加锁有什么机制？

   > 答：
   >
   > 有些业务逻辑在执行过程中要求对数据进行排他性的访问，于是需要通过一些机制保证在此过程中数据被锁住不会被外界修改，这就是所谓的锁机制。

   1.9 什么是多线程上下文切换？

   > 答：即使是单核CPU也支持多线程执行代码，CPU通过给每个线程分配CPU时间片来实现这个机制。时间片是CPU分配给各个线程的时间，因为时间片非常短，所以CPU通过不停地切换线程执行，让我们感觉多个线程时同时执行的，时间片一般是几十毫秒（ms）
   >
   > 上下文切换过程中，CPU会停止处理当前运行的程序，并保存当前程序运行的具体位置以便之后继续运行。
   >
   > CPU通过时间片分配算法来循环执行任务，当前任务执行一个时间片后会切换到下一个任务。但是，在切换前会保存上一个任务的状态，以便下次切换回这个任务时，可以再次加载这个任务的状态
   >
   > 从任务保存到再加载的过程就是一次上下文切换

   1.10 ThreadLocal的设计理念和作用？

   > 答：Java中的ThreadLocal类允许我们创建只能被同一个线程读写的变量。因此，如果一段代码含有一个ThreadLocal变量的引用，即使两个线程同时执行这段代码，它们也无法访问到对方的ThreadLocal变量
   >
   > **如何创建ThreadLocal变量**
   >
   > 以下代码展示了如何创建一个ThreadLocal变量：
   >
   > `private ThreadLocal myThreadLocal = new ThreadLocal();`
   >
   > 通过这段代码实例化了一个ThreadLocal对象。我们只需要实例化对象一次，并且也不需要知道它是被哪个线程实例化。虽然所有的线程都能访问到这个ThreadLocal实例，但是每个线程却只能访问到自己通过调用ThreadLocal的set()方法设置的值。即使是两个不同的线程在同一个ThreadLocal对象上设置了不同的值，他们仍然无法访问到对方的值。
   >
   > **如何访问ThreadLocal变量**
   >
   > 一旦创建了一个ThreadLocal变量，你可以通过如下代码设置某个需要保存的值：
   >
   > `myThreadLocal.set("A thread local value”);`
   >
   > 可以通过下面方法读取保存在ThreadLocal变量中的值：
   >
   > `String threadLocalValue = (String) myThreadLocal.get();`
   >
   > get()方法返回一个Object对象，set()对象需要传入一个Object类型的参数。
   >
   > *为ThreadLocal指定泛型类型*
   >
   > `public static ThreadLocal<String> myThreadLocal = new ThreadLocal<String>();`
   >
   > 我们可以创建一个指定泛型类型的ThreadLocal对象，这样我们就不需要每次对使用get()方法返回的值作强制类型转换了。下面展示了指定泛型类型的ThreadLocal例子：
   >
   > **InheritableThreadLocal**
   >
   > `public static ThreadLocal<Integer> threadLocal = new InheritableThreadLocal<Integer>();`
   >
   > InheritableThreadLocal类是ThreadLocal类的子类。ThreadLocal中每个线程拥有它自己的值，与ThreadLocal不同的是，InheritableThreadLocal允许一个线程以及该线程创建的所有子线程都可以访问它保存的值。
   >
   > InheritableThreadLocal 原理 
   >
   > ```java
   > private ThreadLocalMap(ThreadLocalMap parentMap){
   >   entry[] parentTable = parentMap.table;
   >   int len = parentTable.length;
   >   setThreshold[len];
   >   for(int j = 0;j<len ; j++){
   >     Entry e = parentTable[j];
   >     if(e !=null){
   >       @SuppressWarnings("unchecked")
   >       ThreadLocal<Onject> key = (ThreadLocal<Object>)e.get();
   >       if(key !=null){
   >         Object value = key.childValue(e.value);
   >         Entry c = new Entry(key,value);
   >         int h = key.threadLocalHashCode & (len - 1);
   >         while(table[h] !=null){
   >           h = nextIndex(h,len);
   >           table[h] = c;
   >           size++;
   >         }
   >       }
   >     }
   >   }
   > }
   > 
   > //当我们创建一个新的线程的时候X，X线程就会有 ThreadLocalMap 类型的 inheritableThreadLocals ，因为它是 Thread 类的一个属性。
   > //然后先得到当前线程存储的这些值，例如Entry[] parentTable = parentMap.table; 。再通过一个 for 循环，不断的把当前线程的这些值复制到我们新创建的线程X 的inheritableThreadLocals 中
   > ```

   1.11 Semaphore有什么作用？

   > 答：Semaphore就是一个信号量，它的作用是限制某段代码块的并发数。
   >
   >  
   >
   > Semaphore有一个构造函数，可以传入一个int型整数n，表示某段代码最多只有n个线程可以访问，
   >
   > 如果超出了n，那么请等待，等到某个线程执行完毕这段代码块，下一个线程再进入。
   >
   > 由此可以看出如果Semaphore构造函数中传入的int型整数n=1，相当于变成了一个synchronized了。
   >
   > Semaphore类位于java.util.concurrent包下，它提供了2个构造器：
   >
   > ```java
   > //参数permits表示许可数目，即同时可以允许多少线程进行访问
   > public Semaphore (int permits){
   >   sync = new NonfairSync(permits);
   > }
   > //这个多了一个参数（fair表示是否是公平的，即等待时间越久的是否越先获取许可）
   > public Semaphore (int permits,boolean fair){
   >   sync = (fair)? new FairSyne(peimits):new NonfairSync(permits);
   > }
   > ```
   >
   > Semaphore类中比较重要的几个方法，首先是acquire()、release()方法：
   >
   > acquire()用来获取一个许可，若无许可能够获得，则会一直等待，直到获得许可。
   >
   > release()用来释放许可。注意，在释放许可之前，必须先获获得许可

   1.12  ConcurrentHashMap的并发度是什么？

   > **答：** ConcurrentHashMap的并发度就是segment的大小，默认为16，这意味着最多同时可以有16条线程操作ConcurrentHashMap，这也是ConcurrentHashMap对Hashtable的最大优势。

   1.13 Condition接口及其实现原理？

   > 答：在java.util.concurrent包中，有两个很特殊的工具类，Condition和ReentrantLock，使用过的人都知道，ReentrantLock（重入锁）是jdk的concurrent包提供的一种独占锁的实现
   >
   > 我们知道在线程的同步时可以使一个线程阻塞而等待一个信号，同时放弃锁使其他线程可以能竞争到锁
   >
   > 在synchronized中我们可以使用Object的wait()和notify方法实现这种等待和唤醒
   >
   > 但是在Lock中怎么实现这种wait和notify呢？
   >
   > 答案是Condition，学习Condition主要是为了方便以后学习blockqueue和concurrenthashmap的源码，同时也进一步理解ReentrantLock。
   >
   > ReentrantLock和Condition的使用方式通常是这样的：
   >
   > ```java
   > public static void main(String [] args){
   >   final ReentrantLock reentrantLock = new ReentrantLock();
   >   final Condition condition = reentrantLock.newCondition();
   >   Thread thread = new Thread((Runnable)()->{
   >     try{
   >       reentrantLock.lock();
   >       System.oup.println("等待新的信号" + this);
   >       condition.wait();
   >     }catch(InterruptedException e){
   >       e,printStackTrance();
   >     }
   >     System.out.println("拿到一个信号！" +this);
   >     reentrantLock.unlock();
   >   },"waitThread1");
   >   thread.start();
   >   Thread thread1 = new Thread((Runnable)()->{
   >     reentrantLock.lock();
   >     System.oup.println("拿到锁了" );
   >     try{
   >       Thread.sleep(3000)
   >     }catch(InterruptedException e){
   >       e,printStackTrance();
   >     }
   >     condition.singalAll();
   >     System.oup.println("发了一个信号" );
   >     reentrantLock.unlock();
   >   },"signalThread");
   > }
   > ```
   >
   > Condition是一个多线程间协调通信的工具类，使得某个，或者某些线程一起等待某个条件（Condition）,只有当该条件具备( signal 或者 signalAll方法被带调用)时 ，这些等待线程才会被唤醒，从而重新争夺锁。
   >
   > Condition自己也维护了一个队列，该队列的作用是维护一个等待signal信号的队列，两个队列的作用是不同，事实上，每个线程也仅仅会同时存在以上两个队列中的一个，流程是这样的
   >
   > 线程1调用reentrantLock.lock时，线程被加入到AQS的等待队列中。
   >
   > 线程1调用await方法被调用时，该线程从AQS中移除，对应操作是锁的释放。
   >
   > 接着马上被加入到Condition的等待队列中，以为着该线程需要signal信号。
   >
   > 线程2，因为线程1释放锁的关系，被唤醒，并判断可以获取锁，于是线程2获取锁，并被加入到AQS的等待队列中。
   >
   > 线程2调用signal方法，这个时候Condition的等待队列中只有线程1一个节点，于是它被取出来，并被加入到AQS的等待队列中。 注意，这个时候，线程1 并没有被唤醒。
   >
   > signal方法执行完毕，线程2调用reentrantLock.unLock()方法，释放锁。这个时候因为AQS中只有线程1，于是，AQS释放锁后按从头到尾的顺序唤醒线程时，线程1被唤醒，于是线程1回复执行。
   >
   > 直到释放所整个过程执行完毕。
   >
   > 可以看到，整个协作过程是靠结点在AQS的等待队列和Condition的等待队列中来回移动实现的，Condition作为一个条件类，很好的自己维护了一个等待信号的队列，并在适时的时候将结点加入到AQS的等待队列中来实现的唤醒操作。

2. 数据库

   2.1 Mysql索引结构类型？哈希索引和B+树索引比较？

   > 答：
   >
   > 索引类型: B-TREE索引，哈希索引
   > B-TREE索引加速了数据访问，因为存储引擎不会扫描整个表得到需要的数据。相反，它从根节点开始。根节点保存了指向子节点的指针，并且存储引擎会根据指针寻找数据。它通过查找节点页中的值找到正确的指针，节点页包含子节点的指针，并且存储引擎会根据指针寻找数据。它通过查找节点页中的值找到正确的指针，节点页包含子节点中值的上界和下界。最后，存储引擎可能无法找到需要的数据，也可能成功地找到包含数据的叶子页面。
   > 例：B-TREE索引 对于以下类型查询有用。匹配全名、匹配最左前缀、匹配列前缀、匹配范围值、精确匹配一部分并且匹配某个范围中的另一部分；
   > B-TREE索引的局限：如果查找没有从索引列的最左边开始，它就没什么用处。不能跳过索引中的列，存储引擎不能优先访问任何在第一个范围条件右边的列。例：如果查询是where last_name=’Smith’ AND first_name LIKE ‘J%’ AND dob=’1976-12-23’;访问就只能使用索引的头两列，因为LIKE是范围条件。
   >
   > 哈希索引建立在哈希表的基础上，它只对使用了索引中的每一列的精确查找有用。对于每一行，存储引擎计算出了被索引列的哈希码，它是一个较小的值，并且有可能和其他行的哈希码不同。它把哈希码保存在索引中，并且保存了一个指向哈希表中每一行的指针。
   >
   > 因为索引只包含了哈希码和行指针，而不是值自身，MYSQL不能使用索引中的值来避免读取行。
   > MYSQL不能使用哈希索引进行排序，因为它们不会按序保存行。
   > 哈希索引不支持部分键匹配，因为它们是由被索引的全部值计算出来的。也就是说，如果在（A，B）两列上有索引，并且WHERE子句中只使用了A，那么索引就不会起作用。
   > 哈希索引只支持使用了= IN（）和的相等比较。它们不能加快范围查询。例如WHERE  price > 100;
   > 访问哈希索引中的数据非常快，除非碰撞率很高。当发生碰撞的时候，存储引擎必须访问链表中的每一个行指针，然后逐行进行数据比较，以确定正确的数据。如果有很多碰撞，一些索引维护操作就有可能会变慢。

   2.2 事务特性？

   > 答：
   >
   > 1. 原子性（Atomicity）：事务作为一个整体被执行 ，要么全部执行，要么全部不执行；
   > 2. 一致性（Consistency）：在事务开始之前和事务结束以后，数据库的完整性没有被破坏。这表示写入的资料必须完全符合所有的预设规则，这包含资料的精确度、串联性以及后续数据库可以自发性地完成预定的工作；
   > 3. 隔离性（Isolation）：多个事务并发执行时，一个事务的执行不应影响其他事务的执行，然后你可以扯到隔离级别；
   > 4. 持久性（Durability）：一个事务一旦提交，对数据库的修改应该永久保存。

   2.3 mysql数据库的默认存储引擎，有什么特点？

   > 答：
   >
   > MyISAM
   > MyISAM引擎是MySQL 5.1及之前版本的默认引擎，它的特点是：
   >
   > 不支持行锁，读取时对需要读到的所有表加锁，写入时则对表加排它锁
   > 不支持事务
   > 不支持外键
   > 不支持崩溃后的安全恢复
   > 在表有读取查询的同时，支持往表中插入新纪录
   > 支持BLOB和TEXT的前500个字符索引，支持全文索引
   > 支持延迟更新索引，极大提升写入性能
   > 对于不会进行修改的表，支持压缩表，极大减少磁盘空间占用
   >
   > InnoDB
   > InnoDB在MySQL 5.5后成为默认索引，它的特点是：
   >
   > 支持行锁，采用MVCC来支持高并发
   > 支持事务
   > 支持外键
   > 支持崩溃后的安全恢复
   > 不支持全文索引
   >
   > 总体来讲，MyISAM适合SELECT密集型的表，而InnoDB适合INSERT和UPDATE密集型的表
   >

   2.4 mysql的事务隔离级别，分别解决什么问题

   > 答：
   >
   > READ_UNCOMMITTED（未授权读取）: 最低的隔离级别，允许读取尚未提交的数据变更，可能会导致脏读、幻读或不可重复读
   >
   > READ_COMMITTED（授权读取）: 允许读取并发事务已经提交的数据，可以阻止脏读，但是幻读或不可重复读仍有可能发生
   >
   > REPEATABLE_READ（可重复读）: 对同一字段的多次读取结果都是一致的，除非数据是被本身事务自己所修改，可以阻止脏读和不可重复读，但幻读仍有可能发生。
   >
   > SERIALIZABLE（串行）: 最高的隔离级别，完全服从ACID的隔离级别。所有的事务依次逐个执行，这样事务之间就完全不可能产生干扰，也就是说，该级别可以防止脏读、不可重复读以及幻读。但是这将严重影响程序的性能。通常情况下也不会用到该级别。
   >
   > 这里需要注意的是：Mysql 默认采用的 REPEATABLE_READ隔离级别 Oracle 默认采用的 READ_COMMITTED隔离级别.
   >
   > 事务隔离机制的实现基于锁机制和并发调度。其中并发调度使用的是MVVC（多版本并发控制），通过保存修改的旧版本信息来支持并发一致性读和回滚等特性。

   2.5 SQL慢查询的常见优化步骤？除此之外还有什么方法优化？

   2.6 悲观锁、乐观锁（select for update）,写出sql实现

   2.7 数据库水平切分和垂直切分的设计思路和切分顺序

   > 

   2.8 为什么MyISAM查询性能好？

   > 答：
   >
   > MyISAM和 innodb 的实现上的区别?
   >
   > 1.一个聚簇一个非聚簇
   >
   >   聚簇索引保证关键字的值相近的元组存储的物理位置也相同（所以字符串类型不宜建立聚簇索引，特别是随机字符串，会使得系统进行大量的移动操作），且一个表只能有一个聚簇索引。因为由存储引擎实现索引，所以，并不是所有的引擎都支持聚簇索引。目前，只有solidDB和InnoDB支持。
   >
   > INNODB在做SELECT的时候，要维护的东西比MYISAM引擎多很多:
   > 1）数据块，INNODB要缓存，MYISAM只缓存索引块，  这中间还有换进换出的减少；
   >
   >
   > 2）innodb寻址要映射到块，再到行，MYISAM记录的直接是文件的OFFSET，定位比INNODB要快
   > (phil 注: myisam 更新频率低,所以 索引变更少 . 所以允许每次更新 即更新主索引,也更新付索引,更新 offset)
   >
   > 3）INNODB还需要维护MVCC一致；虽然你的场景没有，但他还是需要去检查和维护
   > MVCC (Multi-Version Concurrency Control)多版本并发控制
   > (phil 注: 由于没有了多行,不需要判断 选取可见的那行数据)
   >   myisam 表锁.牺牲了写性能,提高了读性能.
   >
   > 注释：
   > InnoDB：通过为每一行记录添加两个额外的隐藏的值来实现MVCC，这两个值一个记录这行数据何时被创建，另外一个记录这行数据何时过期（或者被删除）。但是InnoDB并不存储这些事件发生时的实际时间，相反它只存储这些事件发生时的系统版本号。这是一个随着事务的创建而不断增长的数字。每个事务在事务开始时会记录它自己的系统版本号。每个查询必须去检查每行数据的版本号与事务的版本号是否相同。让我们来看看当隔离级别是REPEATABLEREAD时这种策略是如何应用到特定的操作的：
   > 　　SELECT InnoDB必须每行数据来保证它符合两个条件：
   > 　　1、InnoDB必须找到一个行的版本，它至少要和事务的版本一样老(也即它的版本号不大于事务的版本号)。这保证了不管是事务开始之前，或者事务创建时，或者修改了这行数据的时候，这行数据是存在的。
   > 　　2、这行数据的删除版本必须是未定义的或者比事务版本要大。这可以保证在事务开始之前这行数据没有被删除

   2.9 执行某次操作，前50次成功，第51次失败，a.全部回滚；b. 前50次提交 第51次抛异常 场景分别如何配置（传播特性）

   > 答：
   >
   > a、全部回滚      父类方法加事务PROPAGATION_REQUIRED
   >
   > b、第51次抛异常     父类方法加事务PROPAGATION_REQUIRED ,子类方法加事务PROPAGATION_REQUIRES_NEW
   >
   > | 传播行为                  | 官方含义                                                     | 简单理解                                                     |
   > | ------------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
   > | PROPAGATION_REQUIRED      | 表示当前方法必须在一个事务中运行。如果一个现有事务正在进行中，该方法将在那个事务中运行，否则就要开始一个新事务 | 有事务就用已有的，没有就重新开启一个                         |
   > | PROPAGATION_SUPPORTS      | 表示当前方法不需要事务性上下文，但是如果有一个事务已经在运行的话，它也可以在这个事务里运行 | 有事务就用已有的，没有也不会重新开启                         |
   > | PROPAGATION_MANDATORY     | 表示该方法必须运行在一个事务中。如果当前没有事务正在发生，将抛出一个异常 | 必须要有事务，没事务抛异常                                   |
   > | PROPAGATION_REQUIRES_NEW  | 表示当前方法必须在它自己的事务里运行。一个新的事务将被启动，而且如果有一个现有事务在运行的话，则将在这个方法运行期间被挂起 | 开启新事务，若当前已有事务，挂起当前事务                     |
   > | PROPAGATION_NOT_SUPPORTED | 表示该方法不应该在一个事务中运行。如果一个现有事务正在进行中，它将在该方法的运行期间被挂起 | 不需要事务，若当前已有事务，挂起当前事务                     |
   > | PROPAGATION_NEVER         | 表示当前的方法不应该在一个事务中运行。如果一个事务正在进行，则会抛出一个异常 | 不需要事务，若当前已有事务，抛出异常                         |
   > | PROPAGATION_NESTED        | 表示如果当前正有一个事务在进行中，则该方法应当运行在一个嵌套式事务中。被嵌套的事务可以独立于封装事务进行提交或回滚。如果封装事务不存在，行为就像PROPAGATION_REQUIRES一样 | 嵌套事务，如果外部事务回滚，则嵌套事务也会回滚！！！外部事务提交的时候，嵌套它才会被提交。嵌套事务回滚不会影响外部事务。 |

3. spring

   3.1 @Autowired的实现原理？

   3.2 Bean的默认作用范围是什么？其它的作用范围？

   > 答：
   >
   > singleton：Spring IoC容器中只会存在一个共享的Bean实例，无论有多少个Bean引用它，始终指向同一对象。Singleton作用域是Spring中的缺省作用域(默认)。
   >
   >  prototype：每次通过Spring容器获取prototype定义的bean时，容器都将创建一个新的Bean实例，每个Bean实例都有自己的属性和状态，而singleton全局只有一个对象。
   >
   > request：在一次Http请求中，容器会返回该Bean的同一实例。而对不同的Http请求则会产生新的Bean，而且该bean仅在当前Http Request内有效。
   >
   > session：在一次Http Session中，容器会返回该Bean的同一实例。而对不同的Session请求则会创建新的实例，该bean实例仅在当前Session内有效。
   >
   > global Session：在一个全局的Http Session中，容器会返回该Bean的同一个实例，仅在使用portlet context时有效。

   3.3 介绍一下aop？

   > 答：
   >
   > AOP（Aspect-Oriented Programming）指一种程序设计范型，该范型以一种称为切面（aspect）的语言构造为基础，切面是一种新的模块化机制，用来描述分散在对象、类或方法中的横切关注点（crosscutting concern）。
   >
   > a. 连接点（Joinpoint）：程序执行的某个特定位置（如：某个方法调用前、调用后，方法抛出异常后）。一个类或一段程序代码拥有一些具有边界性质的特定点，这些代码中的特定点就是连接点。Spring仅支持方法的连接点。 
   >
   > b. 切点（Pointcut）：如果连接点相当于数据中的记录，那么切点相当于查询条件，一个切点可以匹配多个连接点。Spring AOP的规则解析引擎负责解析切点所设定的查询条件，找到对应的连接点。 
   >
   > c. 增强（Advice）：增强是织入到目标类连接点上的一段程序代码。Spring提供的增强接口都是带方位名的，如：BeforeAdvice、AfterReturningAdvice、ThrowsAdvice等。通过AOP将横切关注功能加到原有的业务逻辑上，这就是对原有业务逻辑的一种增强，这种增强可以是前置增强、后置增强、返回后增强、抛异常时增强和包围型增强。
   >
   > d. 引介（Introduction）：引介是一种特殊的增强，它为类添加一些属性和方法。这样，即使一个业务类原本没有实现某个接口，通过引介功能，可以动态的未该业务类添加接口的实现逻辑，让业务类成为这个接口的实现类。 
   >
   > e. 织入（Weaving）：织入是将增强添加到目标类具体连接点上的过程，AOP有三种织入方式：①编译期织入：需要特殊的Java编译期（例如AspectJ的ajc）；②装载期织入：要求使用特殊的类加载器，在装载类的时候对类进行增强；③运行时织入：在运行时为目标类生成代理实现增强。Spring采用了动态代理的方式实现了运行时织入，而AspectJ采用了编译期织入和装载期织入的方式。 
   >
   > f. 切面（Aspect）：切面是由切点和增强（引介）组成的，它包括了对横切关注功能的定义，也包括了对连接点的定义。

   3.4 spring 框架中bean的生命周期？

   > 答：
   >
   > ① Spring IoC容器找到关于Bean的定义并实例化该Bean。 
   >
   > ② Spring IoC容器对Bean进行依赖注入。 
   >
   > ③ 如果Bean实现了BeanNameAware接口，则将该Bean的id传给setBeanName方法。 
   >
   > ④ 如果Bean实现了BeanFactoryAware接口，则将BeanFactory对象传给setBeanFactory方法。 
   >
   > ⑤ 如果Bean实现了BeanPostProcessor接口，则调用其postProcessBeforeInitialization方法。 
   >
   > ⑥ 如果Bean实现了InitializingBean接口，则调用其afterPropertySet方法。 
   >
   > ⑦ 如果有和Bean关联的BeanPostProcessors对象，则这些对象的postProcessAfterInitialization方法被调用。 
   >
   > ⑧ 当销毁Bean实例时，如果Bean实现了DisposableBean接口，则调用其destroy方法。 

   3.5 什么是IOC和DI？

   > 答：IoC叫控制反转，是Inversion of Control的缩写，DI（Dependency Injection）叫依赖注入，是对IoC更简单的诠释。控制反转是把传统上由程序代码直接操控的对象的调用权交给容器，通过容器来实现对象组件的装配和管理。所谓的"控制反转"就是对组件对象控制权的转移，从程序代码本身转移到了外部容器，由容器来创建对象并管理对象之间的依赖关系。IoC体现了好莱坞原则 - "Don’t call me, we will call you"。依赖注入的基本原则是应用组件不应该负责查找资源或者其他依赖的协作对象。配置对象的工作应该由容器负责，查找资源的逻辑应该从应用组件的代码中抽取出来，交给容器来完成。DI是对IoC更准确的描述，即组件之间的依赖关系由容器在运行期决定，形象的来说，即由容器动态的将某种依赖关系注入到组件之中。
   >
   > *举个例子：一个类A需要用到接口B中的方法，那么就需要为类A和接口B建立关联或依赖关系，最原始的方法是在类A中创建一个接口B的实现类C的实例，但这种方法需要开发人员自行维护二者的依赖关系，也就是说当依赖关系发生变动的时候需要修改代码并重新构建整个系统。如果通过一个容器来管理这些对象以及对象的依赖关系，则只需要在类A中定义好用于关联接口B的方法（构造器或setter方法），将类A和接口B的实现类C放入容器中，通过对容器的配置来实现二者的关联。*
   >
   > 依赖注入可以通过setter方法注入（设值注入）、构造器注入和接口注入三种方式来实现，Spring支持setter注入和构造器注入，通常使用构造器注入来注入必须的依赖关系，对于可选的依赖关系，则setter注入是更好的选择，setter注入需要类提供无参构造器或者无参的静态工厂方法来创建对象。

4. jvm

   4.1 垃圾回收算法有哪些？为什么新生代使用复制算法？

   > 答：
   >
   > 1.标记-清除算法
   >
   > 等待被回收对象的“标记”过程在上文已经提到过，如果在被标记后直接对对象进行清除，会带来另一个新的问题——内存碎片化。如果下次有比较大的对象实例需要在堆上分配较大的内存空间时，可能会出现无法找到足够的连续内存而不得不再次触发垃圾回收。
   >
   > 2.复制算法（Java堆中新生代的垃圾回收算法）
   >
   > 此GC算法实际上解决了标记-清除算法带来的“内存碎片化”问题。首先还是先标记处待回收内存和不用回收的内存，下一步将不用回收的内存复制到新的内存区域，这样旧的内存区域就可以全部回收，而新的内存区域则是连续的。它的缺点就是会损失掉部分系统内存，因为你总要腾出一部分内存用于复制。
   >
   > Java堆中的新生代就使用了GC复制算法。在新生代中又分为了三个区域：Eden 空间、To Survivor空间、From Survivor空间，from survivor 和 to survivor大小相同，且保证一个为empty。
   >
   > 3.标记-压缩算法（或称为标记-整理算法，Java堆中老年代的垃圾回收算法）
   >
   > 对于新生代，大部分对象都不会存活，所以在新生代中使用复制算法较为高效，而对于老年代来讲，大部分对象可能会继续存活下去，如果此时还是利用复制算法，效率则会降低。标记-压缩算法首先还是“标记”，标记过后，将不用回收的内存对象压缩到内存一端，此时即可直接清除边界处的内存，这样就能避免复制算法带来的效率问题，同时也能避免内存碎片化的问题。老年代的垃圾回收称为“Major GC”。

   4.2 讲讲GC机制？

   > 答：
   >
   > JVM分别对新生代和旧生代采用不同的垃圾回收机制
   >
   > 新生代的GC：
   > 新生代通常存活时间较短，因此基于复制算法来进行回收，所谓复制算法就是扫描出存活的对象，并复制到一块新的完全未使用的空间中.
   >
   > 对应于新生代：就是在Eden和其中一个Survivor，复制到另一个之间Survivor空间中，然后清理掉原来就是在Eden和其中一个Survivor中的对象。
   >
   > 新生代采用空闲指针的方式来控制GC触发，指针保持最后一个分配的对象在新生代区间的位置，当有新的对象要分配内存时，用于检查空间是否足够，不够就触发GC。
   >
   > 当连续分配对象时，对象会逐渐从eden到 survivor，最后到老年代。
   >
   > 用javavisualVM来查看，能明显观察到新生代满了后，会把对象转移到旧生代，然后清空继续装载，当旧生代也满了后，就会报outofmemory的异常。
   >
   > 在执行机制上JVM提供了串行GC（SerialGC）、并行回收GC（ParallelScavenge）和并行GC（ParNew）
   >
   > 1）串行GC
   >
   > 在整个扫描和复制过程采用单线程的方式来进行，适用于单CPU、新生代空间较小及对暂停时间要求不是非常高的应用上，是client级别默认的GC方式，
   >
   > 可以通过-XX:+UseSerialGC来强制指定
   >
   > 2）并行回收GC
   >
   > 在整个扫描和复制过程采用多线程的方式来进行，适用于多CPU、对暂停时间要求较短的应用上，是server级别默认采用的GC方式，
   >
   > 可用-XX:+UseParallelGC来强制指定，用-XX:ParallelGCThreads=4来指定线程数
   >
   > 3）并行GC
   >
   > 与旧生代的并发GC配合使用。
   >
   > 老年代的GC：
   > 旧生代与新生代不同，对象存活的时间比较长，比较稳定，因此采用标记（Mark）算法来进行回收，所谓标记就是扫描出存活的对象，然后再进行回收未被标记的对象，回收后对用空出的空间要么进行合并，要么标记出来便于下次进行分配，总之就是要减少内存碎片带来的效率损耗。在执行机制上JVM提供了串行 GC（SerialMSC）、并行GC（parallelMSC）和并发GC（CMS），具体算法细节还有待进一步深入研究。
   >
   > 以上各种GC机制是需要组合使用的。

   4.3 java怎么进行垃圾回收的？什么对象会进入老年代？

   > 答：
   >
   > 回收对象
   >
   > 不可达对象：通过一系列的GC Roots的对象作为起点，从这些节点开始向下搜索，搜索所走过的路径称为引用链，当一个对象到GC Roots没有任何引用链相连时则此对象是不可用的。
   > GC Roots包括：虚拟机栈中引用的对象、方法区中类静态属性引用的对象、方法区中常量引用的对象、本地方法栈中JNI（Native方法）引用的对象。
   >
   > 彻底死亡条件：
   > 条件1：通过GC Roots作为起点的向下搜索形成引用链，没有搜到该对象，这是第一次标记。
   > 条件2：在finalize方法中没有逃脱回收（将自身被其他对象引用），这是第一次标记的清理。
   >
   > 如何回收
   > 新生代因为每次GC都有大批对象死去，只需要付出少量存活对象的复制成本且无碎片所以使用“复制算法”
   > 老年代因为存活率高、没有分配担保空间，所以使用“标记-清理”或者“标记-整理”算法
   >
   > 复制算法：将可用内存按容量划分为Eden、from survivor、to survivor，分配的时候使用Eden和一个survivor，Minor GC后将存活的对象复制到另一个survivor，然后将原来已使用的内存一次清理掉。这样没有内存碎片。
   > 标记-清除：首先标记出所有需要回收的对象，标记完成后统一回收被标记的对象。会产生大量碎片，导致无法分配大对象从而导致频繁GC。
   > 标记-整理：首先标记出所有需要回收的对象，让所有存活的对象向一端移动。
   >
   > 
   >
   > 新生代
   > 进入条件：优先选择在新生代的Eden区被分配。
   >
   > 
   >
   > 老年代
   > 进入条件：
   > 1.大对象，-XX:PretenureSizeThreshold 大于这个参数的对象直接在老年代分配，来避免新生代GC以及分配担保机制和Eden与Survivor之间的复制
   > 2.经过第一次Minor GC仍然存在，能被Survivor容纳，就会被移动到Survivor中，此时年龄为1，当年龄大于预设值就进入老年代
   > 3.如果Survivor中相同年龄所有对象大小的总和大于Survivor空间的一半，年龄大于等于该年龄的对象进入老年代
   > 4.如果Survivor空间无法容纳新生代中Minor GC之后还存活的对象

   4.4 jvm的内存模型 jmm？

   > 1、程序计数器：是线程私有区，是内存中一块较小的区域，是当前线程执行的字节码指令的行号指示器，如果线程执行的是Java方法，程序计数器记录的是正在执行的虚拟机字节码指令的地址，如果执行的是native方法，程序计数器存储的是undefined，此区域是内存中唯一一块没有规定任何OutOfMemoryError（内存溢出）情况的区域，为什么？因为我们不需要操作该区域，该区域是内部维护的。
   >
   > 2、虚拟机栈：是线程私有的，该区域所描述的是Java方法执行的动态内存模型，每个方法在执行的时候都会创建一个栈帧，用来存储局部变量表，操作数栈，动态链接，方法出口等信息，局部变量表存放的是编译期可知的基本数据类型，引用类型，returnAddress等，局部变量表的内存在编译期完成分配，进入方法后，这个方法需在帧中分配多少内存是固定的，在方法运行期间不会改变局部变量表的大小。如果说栈帧堆满了整个栈，会出现StackOverflowError（栈溢出）异常，栈也可以申请更大的内存，如果申请不到，会抛出OutOfMemoryError异常。
   >
   > 3、本地方法栈：是为本地的native方法服务的，其他的都和虚拟机栈一样。
   >
   > 4、堆：线程共享的一块区域，用来存放对象实例的（由于现在有了逃逸分析技术，也可以将对象分配在栈上），该区域是垃圾回收的主要区域，垃圾回收主要是分代回收，有年轻代和老年代，堆可以是物理上不连续的区域，只要逻辑上连续即可。在堆中分配内存的方法有碰撞指针（前提是区域绝对规整，注意多线程同步问题，可以采用CAS原理加失败重试实现或者本地线程分配缓冲）和空闲列表（不是规整的内存，就是有一个表记录空闲的内存，然后分配后，从该表中去除），堆空间不足时会出现OutOfMemoryError异常。
   >
   > 5、方法区：线程共享的区域，存储JVM加载的类信息（类的版本，字段，方法，接口），常量，静态变量以及即时编译后的代码等数据。方法区还有一块运行时常量池，class文件中的常量池在类加载后就被放入运行时常量池，运行时常量池相对于class文件的常量池具有动态性，可以在运行期间通过intern将常量放入运行时常量池中，方法区空间不足时会抛出OutOfMemoryError异常。
   >
   > 6、除了Java虚拟机规定的这几块区域以外呢，还存在一个堆外内存，即直接内存，直接内存能减少IO时的内存复制了，实现零拷贝，而且没有GC，减少了垃圾回收的工作，加快了复制的速度，该区域也难以控制，如果内存泄漏很难排查。

   4.5 GC的两种判定方法？

   > 答：
   >
   > 引用计数：给一个对象设置一个计数器，当被引用一次就加1，当引用失效的时候就减1，如果该对象长时间保持为0值，则该对象将被标记为回收。优点：算法简单，效率高，缺点：很难解决对象之间的相互循环引用问题。
   >
   > 引用链（可达性分析）：现在主流的gc都采用可达性分析算法来判断对象是否已经死亡。可达性分析：通过一系列成为GC Roots的对象作为起点，从这些起点向下搜索，搜索所走过的路径成为引用链，当一个对象到引用链没有相连时，则判断该对象已经死亡。
   >
   > 可作为gc roots的对象：虚拟机栈（本地方法表）中引用的对象（因为在栈内，被线程引用），方法区中类静态属性引用的对象，方法区中常量引用的（常量存放在常量池中，常量池是方法区的一部分）对象，native方法引用的对象
   >
   > 引用计数和引用链是只是用来标记，判断一个对象是否失效，而不是用来清除。

   4.6 GC的三种收集方法？

   > 答：
   >
   > 标记清除：直接将要回收的对象标记，发送gc的时候直接回收：特点回收特别快，但是回收以后会造成很多不连续的内存空间，因此适合在老年代进行回收，CMS(current mark-sweep)，就是采用这种方法来会后老年代的。
   >
   > 标记整理：就是将要回收的对象移动到一端，然后再进行回收，特点：回收以后的空间连续，缺点：整理要花一定的时间，适合老年代进行会后，parallel Old（针对parallel scanvange gc的） gc和Serial old就是采用该算法进行回收的。
   >
   > 复制算法：将内存划分成原始的是相等的两部分，每次只使用一部分，这部分用完了，就将还存活的对象复制到另一块内存，将要回收的内存全部清除。这样只要进行少量的赋值就能够完成收集。比较适合很多对象的回收，同时还有老年代对其进行担保。（serial new和parallel new和parallel scanvage）
   >
   > 优化收集方法：对复制算法的优化：并不是将两块内存分配同等大小，可以将存活率低的区域大一些，而让回收后存活的对象所占的区域小一些，不够的内存由老年代的内存来保证，这样复制算法的空闲的空间减少了。
   >
   > 两个survival区域的是为了减少风险率，有一个survivor区要参与回收，也要参与存储，只要只有10%的空间浪费，同时也减少对老年代的依赖。

   4.7 GC收集器有哪些？CMS收集器与G收集器的特点？

   > 答：
   >
   > 串行的，也就是采用单线程（比较老了），分类：serial new（收集年轻代，复制算法）和serial old（收集老年代，标记整理），缺点：单线程，进行垃圾回收时暂时所有的用户线程。优点：实现简单。
   >
   > 并行的，采用多线程，对于年轻代有两个： parallel new（简称ParNew）（参考serial new的多线程版本）和parallel scavenge；parallel scavenge是一个针对年轻代的垃圾回收器，采用复制算法，主要的优点是进行垃圾回收时不会停止用户线程（不会发生stop all world）
   >
   > 老年代回收器也有两种：Parallel old是parallel scavenge的我老年代设计的。CMS（并发标记清除），它采用标记清除算法，采用这种的优点就是快咯，因此会尽快的进行回收，减少停顿时间。
   >
   > G1收集器，年轻代和老年代通吃，最新一代的技术。面向服务器端的垃圾收集器（并行+并发的垃圾收集器）。

   4.8 Minor GC与Full GC分别在什么时候发生？

   > 答：
   >
   > Minor GC发生：当jvm无法为新的对象分配空间的时候就会发生minor gc，所以分配对象的频率越高，也就越容易发生minor gc。
   >
   > Full GC：发生GC有两种情况，①当老年代无法分配内存的时候，会导致Full GC,②当发生Minor GC的时候可能触发Full GC，由于老年代要对年轻代进行担保，由于进行一次垃圾回收之前是无法确定有多少对象存活，因此老年代并不能清除自己要担保多少空间，因此采取采用动态估算的方法：也就是上一次回收发送时晋升到老年代的对象容量的平均值作为经验值，这样就会有一个问题，当发生一次Minor GC以后，存活的对象剧增（假设小对象），此时老年代并没有满，但是此时平均值增加了，会造成发生Full GC。

   4.9  双亲委派模型：Bootstrap ClassLoader、Extension ClassLoader、ApplicationClassLoader？

   > 答：
   >
   > 定义：如果父类加载器可以完成类加载任务，就成功返回，倘若父类加载器无法完成此加载任务，子加载器才会尝试自己去加载，这就是**双亲委派模式**。
   >
   > 优点：采用双亲委派模式的是好处是Java类随着它的类加载器一起具备了一种带有优先级的层次关系，通过这种层级关可以避免类的重复加载，当父亲已经加载了该类时，就没有必要子ClassLoader再加载一次。其次防止恶意覆盖Java核心API。
   >
   > 三次大型破坏双亲委派模式的事件：
   >
   > 1. 在双亲委派模式出来之前，用户继承ClassLoader就是为了重写loadClass方法，但双亲委派模式需要这个方法，所以1.2之后添加了findClass供以后的用户重写
   > 2. 如果基础类要调回用户的代码，如JNDI/JDBC需要调用ClassPath下的自己的代码来进行资源管理，Java团队添加了一个线程上下文加载器，如果该加载器没有被设置过，那么就默认是应用程序类加载器
   > 3. 为了实现代码热替换，OSGi是为了实现自己的类加载逻辑，用平级查找的逻辑替换掉了向下传递的逻辑。但其实可以不破坏双亲委派逻辑而是自定义类加载器来达到代码热替换。

   4.10  分派：静态分派与动态分派？

   > 

   4.11 Full GC次数太多了，如何优化？

   > 答：
   >
   > 说明可能有promotion问题和老年代空间不足的问题。可以减小存活区，提高阈值，增大老年代等。

   4.12 直接内存如何管理？

   > 答：
   >
   > 直接内存是堆外内存，通过堆内的引用来连接，回收引用时也会通过追踪算法去回收直接内存。直接内存不受到jvm管理，所以适合用作缓冲区。

   4.13 jvm调优？

   > 答：
   >
   > 前提：在进行GC优化之前，需要确认项目的架构和代码等已经没有优化空间
   >
   > 目的：优化JVM垃圾收集性能从而增大吞吐量或减少停顿时间，让应用在某个业务场景上发挥最大的价值。吞吐量是指应用程序线程用时占程序总用时的比例。暂停时间是应用程序线程让与GC线程执行而完全暂停的时间段
   >
   > 对于交互性web应用来说，一般都是减少停顿时间，所以有以下方法：
   >
   > 如果应用存在大量的短期对象，应该选择较大的年轻代；如果存在相对较多的持久对象，老年代应该适当增大
   > 让大对象进入年老代。可以使用参数-XX:PetenureSizeThreshold 设置大对象直接进入年老代的阈值。当对象的大小超过这个值时，将直接在年老代分配
   > 设置对象进入年老代的年龄。如果对象每经过一次 GC 依然存活，则年龄再加 1。当对象年龄达到阈值时，就移入年老代，成为老年对象
   > 使用关注系统停顿的 CMS 回收器

5. 网络

   5.1 nginx 轮询的实现原理？

   > 答：
   >
   > 由于不同服务器的配置、部署的应用不同，其处理能力会不一样。所以，加权轮询算法的原理就是：根据服务器的不同处理能力，给每个服务器分配不同的权值，使其能够接受相应权值数的服务请求。
   >
   > 在Nginx加权轮询算法中，每个节点有三个权重变量
   >
   > weight : 配置的权重，即在配置文件或初始化时约定好的每个节点的权重
   >
   > currentWeight : 节点当前权重，会一直变
   >
   > effectiveWeight ：有效权重，初始值为weight, 通讯过程中发现节点异常，则-1 ，之后再次选取本节点，调用成功一次则+1，直达恢复到weight 。 用于健康检查，处理异常节点，降低其权重。
   >
   > 算法逻辑
   >
   > (1) 轮询所有节点，计算当前状态下所有节点的effectiveWeight之和totalWeight；
   >
   > (2) currentWeight = currentWeight + effectiveWeight;  选出所有节点中currentWeight中最大的一个节点作为选中节点；
   >
   > (3) 选中节点的currentWeight = currentWeight - totalWeight；
   >
   > 注：（为了简单清晰，后面的实现不考虑健康检查effectiveWeight这个功能实现，假设所有节点都是100%可用，所以上面的逻辑要把使用effectiveWeight的地方换成weight。

   5.2 nginx 7层负载均衡，转发到多个应用服务器？

   > 答：
   >
   > Nginx的负载均衡实现原理：首先在http模块中配置使用upstream模块定义后台的web server的池子，名为proxy-web，在池子中我们可以添加多台后台webserver，其中状态检查、调度算法都是在池子中配置；然后在serverr模块中定义虚拟主机，但是这个虚拟主机不指定自己的web目录站点，它将使用location匹配url然后转发到上面定义好的web池子中，最后根据调度策略再转发到后台web server上
   >
   > upstream调度算法介绍
   >
   > 1.rr轮询（默认）
   >
   >  按照请求顺序分配到每个RS，和lvs中的rr算法一样，如果RS宕机，会自动剔除，默认情况下只检测80端口，如果RS报402、403、503、504错误，会直接返回给客户端。
   >
   > 2.weight（权重）
   >
   >  在rr的基础上再加上权重（默认是rr+weight），权重轮询和访问成正比，值越大分配的越多，可以根据服务器的配置设置权重，可以解决服务器性能不均进行请求分配的问题
   >
   > 3.ip_hash
   >
   > 解决动态网页session共享问题
   >
   > 每个访问请求按照IP地址的hash值进行分配，ip的hash值只要相同就会被分配到同一台服务器上（lvs负载均衡的-p参数，keepalived配置里的persistence_timeout 50）,该调度算法可以解决动态网页session共享问题，但有时会导致请求分配不均，
   >
   > 提示：由于国内用的都是nat模式，所以hash不适合使用
   >
   > ip_hash不能和其他的算法一块使用，即不能使weight或backup
   >
   > 4.fair（第三方）
   >
   > 按照后端服务器的响应时间来配置，响应时间短的优先分配，比上面的都更智能，此种算法可以按照页面大小和加载时间长短智能的进行负载均衡，nginx本身不支持fair，需要下载nginx的upstrea_fair模块
   >
   > 5.url_hash（第三方）
   >
   > 主要应用于缓存服务器上
   >
   > 按照访问的url来分配请求，让相同的url定向到同一个服务器，后端服务器为缓存服务器的时候效果更显著，在upstream中加入hash语句，server语句中不能写入weight等其他的参数，hash_method是使用的hash算法。
   >
   > 缺点：如果有一台机器宕机了，那就苦了，consistent_hash可以解决这个问题
   >
   > 可以提高后端缓存服务器的效率，nginx本身不支持url_hash的，需要下载hash软件
   >
   > 6.least_conn
   >
   > 最少连接数，哪个连接少就分配到哪台设备
   >
   > 7.consistent_hash
   >
   > 一致性算法

   5.3 tcp协议的三次握手和四次挥手过程？

   > 答：
   >
   > 三次握手建立连接：第一次握手：建立连接时，客户端发送syn包(syn=j)到服务器，并进入SYN_SEND状态，等待服务器确认；第二次握手：服务器收到syn包，必须确认客户的SYN（ack=j+1），同时自己也发送一个SYN包（syn=k），即SYN+ACK包，此时服务器进入SYN_RECV状态；第三次握手：客户端收到服务器的SYN＋ACK包，向服务器发送确认包ACK(ack=k+1)，此包发送完毕，客户端和服务器进入ESTABLISHED状态，完成三次握手。
   >
   > 对于四次挥手，客户端想主动断开，则发送一个FIN指令以后，自己进入FIN_WAIT_1状态，服务端此时知道客户端想要断开，自己进入  CLOSE_WAIT状态，但是此时两端都是还是可以相互通信的，如果此时服务端有数据，则会发送给客户端一个ACK报文（告诉客户端我知道了），客户端接收到ACK则进入FIN_WAIT_2阶段（暂时阶段），然后继续传输数据，数据传输完成以后，然后服务端发送FIN指令，此时客户端接受到FIN指令，自己进入LAST_ACK状态，然后发送一个ACK他本可以马上关闭了，但是客户端并没有马上关闭而是进入TIME_WAIT状态，处在该状态以后保持2RTT（大概四分钟吧）就客户端的Socket就自动关闭了，这是因为可能是最后的那个FIN先收到，而在FIN之前的包还为到达客户端（网络延迟），所以要等一等。
   >
   > ***为什么有FIN_Wait_1和FIN_wait_2呢?***
   >
   > 这是因为第一个发送了fin命令之后，服务端有两种发送情况一种是没有数据发送了。直接发送ACK+FIN，所以FIN_WAI_1理解我第等待fin也就可以了，还有就是服务器还有数据发送，那么他先发给服务端ack，等数据传输完成以后再发送fin，所以这儿理解为等待fin也是可以理解的。
   >
   > 默认是客户端想主动断开，所以发送FIN以后自己就不会主动传输数据了，也就是不会调用write（），但是会调用read（）进行读取，所以服务端关闭socket不需要停留2RTT。
   >
   > ***为什么要三次连接？***
   >
   > 最简单解释，两个人爬山，山顶的人向山脚的人喊了一声，而山脚的人听到了，就回答了一句：知道了，但是他并不知道山顶的人是否听到，这样就会发生很多问题。
   >
   > 两次连接的问题
   >
   > 1：服务端有可能发送一次无用连接，占用服务器资源。
   >
   > 当客户端发送一个syn进行连接，由于网络延迟，此时客户端没有收到ack，服务端也没有收到ack，此时客户端再次发送syn进行连接，这次和服务端建立了连接，然后发送完数据，通信完成，此时第一个syn包来了，服务端以为客户端又来了，因为是两次，所以开放资源和客户端建立连接，然后该连接是无效的。
   >
   > 2：发生死循环（建立连接以后服务端主动发送数据的情况）；
   >
   > 当服务端接受到客户端的连接请求syn包时，发送ack包，然后建立连接，此时就开始向客户端发送数据，但是由于网络不稳定，服务端的ack并没有被客户端收到，但是客户端却收到了服务端发送的数据，但是此时不是客户端想要的ack，丢弃，然后继续发送syn包，服务端不管该syn包，然后继续发送数据，客户端发现该数据还是不是需要的ack，继续发送syn包。一直持续下去。

   5.4  TCP拥塞控制？

   > 答：
   >
   > 拥塞控制算法：“慢启动”（Slow Start）、“拥塞避免”（Congestion voidance）、“快速重传 ”（Fast Retransmit）、“快速恢复”（Fast Recovery）
   >
   > 慢启动：早期开发的TCP应用在启动一个连接时会向网络中发送大量的数据包，这样很容易导致路由器缓存空间耗尽，网络发生拥塞，使得TCP连接的吞吐量急剧下降，一看是先发送一个segment到服务器，服务器正常返回ack以后就发送两个segment，如果服务器正确返回，则继续增减一个发送的segment的数据，也就是逐渐增大拥塞窗口的大小，（2^n）
   >
   > 拥塞避免： 如果按上述慢启动的逻辑继续下去而不加任何控制的话，必然会发生拥塞，因此设置一个动态阈值来控制拥塞窗口的大小，当拥塞窗口的大小小于阈值的大小，就属于慢启动阶段，随着拥塞窗口越来越大，甚至超过了阈值，则网络会逐渐发生拥堵状况，这时就会将发送阈值降为原来的一般，并把拥塞窗口的大小设置为初始值（发生第一次拥塞以后变成线性增长的发送）
   >
   > 快速重传，（当接收到冗余ack和长时间接受不到对应的ack的时候就，就会发生重新发送对应序列号的分组），当快速重传的时候则将阈值设置为原来的一半，并发送丢失序号的分组。
   >
   > 快速恢复（是对快速重传的补充）： 那么，什么是快速恢复呢？我们通常认为client接收到3个重复的ack后，就会开始快速重传，但是，如果还有更多的重复ack呢，如何处理？这就是快速恢复要做的，事实上，我们可以把快速恢复看作是快速重传的后续处理，它不是一种单独存在的形态。快速重传之后吧马上增大下一个发送分组的数量，也就是阈值+3个segment的大小。为什么要增加3个segment呢，这时因为一个发送端收到了3个ack，就确认有三个分组被正确接收，为了最大利用网络，保证在网络中的分组数量一致，就在增加了3个segment。

   5.5 TCP滑动窗口与回退N针协议？

   > 答：
   >
   > TCP的滑动窗口只在发送端和接收端才有，滑动窗口是用于流量控制的，注意滑动窗口与拥塞窗口的区分，拥塞窗口除了在发送端和接收端有，路由器也是有的。拥塞窗口是用于拥塞控制的（该窗口是试探性窗口，为了最大利用网络，该窗口一直在变动）。
   >
   > 流量控制：用于窗口时接收方的缓存器的大小的窗口才叫滑动窗口。
   >
   > 公式：可以接收窗口大小=缓存器窗口大小-【刚接收到的窗口大小-刚被读取的窗口的大小】，可以接收窗口的大小是要发送到tcp的发送端的。发送方通过接收到大窗口的大小来判断是否可以发送多少数据到接收端才比较合适。
   >
   > 同时在接收端也是有算法的：接收方保证：接收端可接收窗口大小>刚发送的的分组数-刚接受到的分组数的ack，也就是未被确认的分组的大小小于接收方可接受窗口的大小。接收方缓存器窗口大小是固定的。
   >
   > 流控制是一种局部控制机制，其参与者仅仅是发送方和接收方，它只考虑了接收端的接收能力，而没有考虑到网络的传输能力；而拥塞控制则注重于整体，其考虑的是整个网络的传输能力，是一种全局控制机制。正因为流控制的这种局限性，从而导致了拥塞崩溃现象的发生。
   >
   > 回退N步和选择重传都是解决流水线的差错恢复的两中基本方法；
   >
   >  回退N步：就是将各个分组编号，假如滑动窗口的大小是4，那么一次传输过去四个分组，如果对方接受到一个分组，且分组序号的大小比上一个提交分组的序号大1，则发送一个ack给发送端并提交分组，如果发送端接收到ack的ack与base序号相同，则滑动窗口向后移动。如果接受到的分组不是比提交的分组大1，则会丢弃该分组，这样发送端如果在定时器超时的时间之内没有接受到ack，则回重新发送分组；
   >
   > 缺点：就是如果有一个分组没有被接收而被丢弃，那么可能同一个窗口发送过来的好多分组都会被丢弃。这样就造成了网络的浪费，同时滑动窗口越大，虽然网络的利用率越大，但是一点一次传输过去的是base序号的分组失序或者丢失，则之后整个窗口分组都会被重新发送。（GBN协议只需要一个定时器）
   >
   >  
   >
   > 选择重传：由于GBN协议可能会将失序的分组丢掉，其实失序的分组有时候是没有必要被重新传输的，只需要用一个buffer存存好就可以了。选择重传有在发送方每一个分组都有一个定时器（重点，也是缺点），假如滑动窗口大小是4，如果接受方接收到的分组不比上一个提交的分组序号大1，则会将该分组收分组存入buffer中，等下一个正确的分组到来以后和他一起提交，并将刚接手到；而对于接受方来说：如果一个分组未收到确认，如果超过该分组定时器的时间，则将该分组重新发送，如果ack接受到一个base序号的分组，则滑动窗口向后移动，如果滑动窗口接受到的序号不是base序号的ack，则会将base后面序号的ack先确认，但是此时发送方的滑动窗口并不会向后滑动，只有base序号的ack回来以后滑动窗口才会向后移动。（SR选择重传在没有收到想要的序号的时候返回的是ack中包含的是想要的序号的ack，而不是刚刚接收到的分组的序号）
   >
   > TCP用于解决流水线的差错恢复方法：使用的协议是GNB协议和SR选择重传的综合：GBN协议是只有一个超时定时器，而SR选择重传每一分组有一个定时器，TCP采用的是设置一个定时器（所有的分组的超时时间就是一样的）。但是在ack确认和接收方序号乱的时候采用的SR协议来实现的。

   5.6  Http怎么处理长连接？（HTTP1.0和HTTP1.1的区别）

   > 答：
   >
   > HTTP 1.0需要使用keep-alive参数来告知服务器端要建立一个长连接，而HTTP1.1默认支持长连接。
   >
   > HTTP是基于TCP/IP协议的，创建一个TCP连接是需要经过三次握手的,有一定的开销，如果每次通讯都要重新建立连接的话，对性能有影响。因此最好能维持一个长连接，可以用个长连接来发多个请求。
   >
   > 节约带宽
   >
   > HTTP 1.1支持只发送header信息(不带任何body信息)，如果服务器认为客户端有权限请求服务器，则返回100，否则返回401。客户端如果接受到100，才开始把请求body发送到服务器。
   >
   > 这样当服务器返回401的时候，客户端就可以不用发送请求body了，节约了带宽。
   >
   > 另外HTTP还支持传送内容的一部分。这样当客户端已经有一部分的资源后，只需要跟服务器请求另外的部分资源即可。这是支持文件断点续传的基础。

   5.7 电脑上访问一个网页，整个过程是怎么样的：DNS、HTTP、TCP、OSPF、IP、ARP？

   > 答：
   >
   > ***DHCP 配置主机信息***
   >
   > 假设主机最开始没有 IP 地址以及其它信息，那么就需要先使用 DHCP 来获取。
   >
   > 主机生成一个 DHCP 请求报文，并将这个报文放入具有目的端口 67 和源端口 68 的 UDP 报文段中。
   >
   > 该报文段则被放入在一个具有广播 IP 目的地址(255.255.255.255) 和源 IP 地址（0.0.0.0）的 IP 数据报中。
   >
   > 该数据报则被放置在 MAC 帧中，该帧具有目的地址 FF:FF:FF:FF:FF:FF，将广播到与交换机连接的所有设备。
   >
   > 连接在交换机的 DHCP 服务器收到广播帧之后，不断地向上分解得到 IP 数据报、UDP 报文段、DHCP 请求报文，之后生成 DHCP ACK 报文，该报文包含以下信息：IP 地址、DNS 服务器的 IP 地址、默认网关路由器的 IP 地址和子网掩码。该报文被放入 UDP 报文段中，UDP 报文段有被放入 IP 数据报中，最后放入 MAC 帧中。
   >
   > 该帧的目的地址是请求主机的 MAC 地址，因为交换机具有自学习能力，之前主机发送了广播帧之后就记录了 MAC 地址到其转发接口的交换表项，因此现在交换机就可以直接知道应该向哪个接口发送该帧。
   >
   > 主机收到该帧后，不断分解得到 DHCP 报文。之后就配置它的 IP 地址、子网掩码和 DNS 服务器的 IP 地址，并在其 IP 转发表中安装默认网关。
   >
   > ***ARP 解析 MAC 地址***
   > 主机通过浏览器生成一个 TCP 套接字，套接字向 HTTP 服务器发送 HTTP 请求。为了生成该套接字，主机需要知道网站的域名对应的 IP 地址。
   >
   > 主机生成一个 DNS 查询报文，该报文具有 53 号端口，因为 DNS 服务器的端口号是 53。
   >
   > 该 DNS 查询报文被放入目的地址为 DNS 服务器 IP 地址的 IP 数据报中。
   >
   > 该 IP 数据报被放入一个以太网帧中，该帧将发送到网关路由器。
   >
   > DHCP 过程只知道网关路由器的 IP 地址，为了获取网关路由器的 MAC 地址，需要使用 ARP 协议。
   >
   > 主机生成一个包含目的地址为网关路由器 IP 地址的 ARP 查询报文，将该 ARP 查询报文放入一个具有广播目的地址（FF:FF:FF:FF:FF:FF）的以太网帧中，并向交换机发送该以太网帧，交换机将该帧转发给所有的连接设备，包括网关路由器。
   >
   > 网关路由器接收到该帧后，不断向上分解得到 ARP 报文，发现其中的 IP 地址与其接口的 IP 地址匹配，因此就发送一个 ARP 回答报文，包含了它的 MAC 地址，发回给主机。
   >
   > ***DNS 解析域名***
   >
   > 知道了网关路由器的 MAC 地址之后，就可以继续 DNS 的解析过程了。
   >
   > 网关路由器接收到包含 DNS 查询报文的以太网帧后，抽取出 IP 数据报，并根据转发表决定该 IP 数据报应该转发的路由器。
   >
   > 因为路由器具有内部网关协议（RIP、OSPF）和外部网关协议（BGP）这两种路由选择协议，因此路由表中已经配置了网关路由器到达 DNS 服务器的路由表项。
   >
   > 到达 DNS 服务器之后，DNS 服务器抽取出 DNS 查询报文，并在 DNS 数据库中查找待解析的域名。
   >
   > 找到 DNS 记录之后，发送 DNS 回答报文，将该回答报文放入 UDP 报文段中，然后放入 IP 数据报中，通过路由器反向转发回网关路由器，并经过以太网交换机到达主机。
   >
   > ***HTTP 请求页面***
   > 有了 HTTP 服务器的 IP 地址之后，主机就能够生成 TCP 套接字，该套接字将用于向 Web 服务器发送 HTTP GET 报文。
   >
   > 在生成 TCP 套接字之前，必须先与 HTTP 服务器进行三次握手来建立连接。生成一个具有目的端口 80 的 TCP SYN 报文段，并向 HTTP 服务器发送该报文段。
   >
   > HTTP 服务器收到该报文段之后，生成 TCP SYN ACK 报文段，发回给主机。
   >
   > 连接建立之后，浏览器生成 HTTP GET 报文，并交付给 HTTP 服务器。
   >
   > HTTP 服务器从 TCP 套接字读取 HTTP GET 报文，生成一个 HTTP 响应报文，将 Web 页面内容放入报文主体中，发回给主机。
   >
   > 浏览器收到 HTTP 响应报文后，抽取出 Web 页面内容，之后进行渲染，显示 Web 页面。

6. 数据结构

   6.1 HashMap的时间复杂度？HashMap中的Hash冲突是怎么解决的？Java8中的HashMap有什么变化？

   > 答：
   >
   > 1.7 版本O（n）
   >
   > 1.8版本 O（logn）
   >
   > 在Java 8 之前，HashMap和其他基于map的类都是通过链地址法解决冲突，它们使用单向链表来存储相同索引值的元素。在最坏的情况下，这种方式会将HashMap的get方法的性能从O(1)降低到O(n)。为了解决在频繁冲突时hashmap性能降低的问题，Java 8中使用平衡树来替代链表存储冲突的元素。这意味着我们可以将最坏情况下的性能从O(n)提高到O(logn)。
   > 在Java 8中使用常量TREEIFY_THRESHOLD来控制是否切换到平衡树来存储。目前，这个常量值是8，这意味着当有超过8个元素的索引一样时，HashMap会使用树来存储它们。
   > 这一改变是为了继续优化常用类。大家可能还记得在Java 7中为了优化常用类对ArrayList和HashMap采用了延迟加载的机制，在有元素加入之前不会分配内存，这会减少空的链表和HashMap占用的内存。
   > 这一动态的特性使得HashMap一开始使用链表，并在冲突的元素数量超过指定值时用平衡二叉树替换链表。不过这一特性在所有基于hash table的类中并没有，例如Hashtable和WeakHashMap。
   > 目前，只有ConcurrentHashMap,LinkedHashMap和HashMap会在频繁冲突的情况下使用平衡树。
   >
   > J
   >
   > DK1.8里对hashmap最大的改变是引入了红黑树，这一点在hash不均匀并且元素个数很多的情况时，对hashmap的性能提升非常大。Hashmap的底层实现是使用一个entry数组存储，默认初始大小16，不过jdk8换了名字叫node，可能是因为引入了树，叫node更合适吧，另外我也不喜欢entry这个名字，不能望文生义，我在刚学的时候还以为是什么神秘的东西呢，其实就是个键值对对象而已。Node里有next引用指向下一个节点，因为hashmap解决冲突的思路是拉链法。
   >
   > JDK7中HashMap采用的是位桶+链表的方式。而JDK8中采用的是位桶+链表/红黑树的方式，当某个位桶的链表的长度超过8的时候，这个链表就将转换成红黑树。因为引入了树，所以其他操作也更复杂了，比如put方法以前只要通过hash计算下标位置，判断该位置有没有元素，如果有就往下遍历，如果存在相同的key就替换value，如果不存在就添加。但是到了8以后，就要判断是链表还是树，如果是链表，插入后还要判断要不要转化成树。不过这些操作都是常量级别的，复杂度还是O（1）的，但是对整体性能提升非常大。链表转换红黑树在treeify方法里实现，给树插入节点在puttreeval方法，修正红黑树是balanceInsertion方法
   >
   > ```java
   >  					 Node<K,V> e; K k;
   >            if (p.hash == hash &&
   >                  ((k = p.key) == key || (key != null && key.equals(k))))                 							e = p;
   >              else if (p instanceof TreeNode)
   >                  e = ((TreeNode<K,V>)p).putTreeVal(this, tab, hash, key, value);
   >              else {
   >                  for (int binCount = 0; ; ++binCount) {
   >                      if ((e = p.next) == null) {
   >                          p.next = newNode(hash, key, value, null);
   >                          if (binCount >= TREEIFY_THRESHOLD - 1) // -1 for 1st
   >                              treeifyBin(tab, hash);
   >                          break;
   >                      }
   >                      if (e.hash == hash &&
   >                          ((k = e.key) == key || (key != null && key.equals(k))))
   >                          break;
   >                      p = e;
   >                  }
   >              }
   >              if (e != null) { // existing mapping for key
   >                  V oldValue = e.value;                 
   >                	 if (!onlyIfAbsent || oldValue == null)
   >                      e.value = value;
   >                  afterNodeAccess(e);
   >                  return oldValue;
   >              }
   > 
   > ```
   >
   > 另外变化比较大的还有扩容机制，也就是resize方法
   >
   > ```java
   > 
   >                     if (e.next == null)
   >                          newTab[e.hash & (newCap - 1)] = e;
   > 										else if (e instanceof TreeNode)
   >                          ((TreeNode<K,V>)e).split(this, newTab, j, oldCap);
   >                     else { // preserve order
   >                          Node<K,V> loHead = null, loTail = null;
   >                          Node<K,V> hiHead = null, hiTail = null;
   >                          Node<K,V> next;
   >                          do {
   >                              next = e.next;
   >                              if ((e.hash & oldCap) == 0) {
   >                                  if (loTail == null)
   >                                      loHead = e;
   >                                  else
   >                                      loTail.next = e;
   >                                  loTail = e;
   >                              }
   >                              else {
   >                                  if (hiTail == null)
   >                                      hiHead = e;
   >                                  else
   >                                      hiTail.next = e;
   >                                  hiTail = e;
   >                              }
   >                          } while ((e = next) != null);
   >                          if (loTail != null) {
   >                              loTail.next = null;
   >                              newTab[j] = loHead;
   >                          }
   >                          if (hiTail != null) {
   >                              hiTail.next = null;
   >                              newTab[j + oldCap] = hiHead;
   >                          }
   > 
   > ```
   >
   > 上面的代码就是三个if-else if-else，分三种情况处理，
   >
   > 1. 表项只有一个键值对时，针对新表计算新的索引位置并插入键值对
   > 2. 表项节点是红黑树节点时（说明这个bin元素较多已经转成红黑树了），调用split方法处理。
   > 3. 表项节点包含多个键值对组成的链表时（拉链法）
   >
   > 第一种情况就是直接对新的数组长度取模计算新索引，放到新数组的相应位置，和jdk7一样的。第二种情况是引入了红黑树后独有的，通过调用一个split方法处理，关于这个方法一会再细说。第三种情况在jdk7里没引入树时也有，但是jdk8里对这种情况也做了算法上的优化。可以看到上面的代码主要也是在处理第三部分。
   >
   > ```java
   > void transfer(Entry[] newTable) {
   >      Entry[] src = table;                   //src引用了旧的Entry数组
   >      int newCapacity = newTable.length;
   >      for (int j = 0; j < src.length; j++) { //遍历旧的Entry数组
   >          Entry<K,V> e = src[j];             //取得旧Entry数组的每个元素
   >          if (e != null) {
   >              src[j] = null;//释放旧Entry数组的对象引用（for循环后，旧的Entry数组不再引用任何对象）
   >              do {
   >                  Entry<K,V> next = e.next;
   >                 int i = indexFor(e.hash, newCapacity); //！！重新计算每个元素在数组中的位置
   >                 e.next = newTable[i]; //标记[1]
   >                 newTable[i] = e;      //将元素放在数组上
   >                 e = next;             //访问下一个Entry链上的元素
   >             } while (e != null);
   >         }
   >     }
   > }
   > ```
   >
   > 这是jdk7里hashmap resize时对每个位桶的链表的处理方式（transfer方法），整体过程就是先新建两倍的新数组，然后遍历旧数组的每一个entry，直接重新计算新的索引位置然后头插法往拉链里填坑（这里因为是新加入的元素插入到链表头，所以顺序会倒置，jdk8里不会）。看jdk8的代码发现好像完全不是这么做的。
   >
   > jdk8的代码里是这么处理的，把链表上的键值对按hash值分成lo和hi两串，lo串的新索引位置与原先相同[原先位置j]，hi串的新索引位置为[原先位置j+oldCap]。这么做的原因是，我们使用的是2次幂的扩展(newCap是oldCap的两倍)，所以，元素的位置要么是在原位置，要么是在原位置再移动2次幂的位置，也就是原索引+oldCap。为啥？自己举个例子就知道了。那怎么判断该假如lo串还是hi串？这个取决于 判断条件if ((e.hash & oldCap) == 0)，如果条件为真，加入lo串，条件为假，加入hi串。那这是为什么？因为这个&运算其实相当于做了一个掩码，查看原来的hash值新增的那个bit是1还是0就好了，是0的话索引没变，是1的话索引变成“原索引+oldCap”。

   6.2 hash和B+树的区别？分别应用于什么场景？哪个比较好？

   6.3 红黑树需要比较大小才能进行插入，是根据什么进行比较的？其它Hash冲突的解决方式？

   

   6.4 谈一下hashmap的死链？

   > 答：
   >
   > 在内部，HashMap使用一个Entry数组保存key、value数据，当一对key、value被加入时，会通过一个hash算法得到数组的下标index，算法很简单，根据key的hash值，对数组的大小取模 hash & (length-1)，并把结果插入数组该位置，如果该位置上已经有元素了，就说明存在hash冲突，这样会在index位置生成链表。
   >
   > 如果存在hash冲突，最惨的情况，就是所有元素都定位到同一个位置，形成一个长长的链表，这样get一个值时，最坏情况需要遍历所有节点，性能变成了O(n)，所以元素的hash值算法和HashMap的初始化大小很重要。
   >
   > 当插入一个新的节点时，如果不存在相同的key，则会判断当前内部元素是否已经达到阈值（默认是数组大小的0.75），如果已经达到阈值，会对数组进行扩容，也会对链表中的元素进行rehash。（如果size超过当前最大容量*负载因子时候会发生resize）
   >
   > ```java
   > void resize(int newCapacity){
   >   Entry[] oldTable = table;
   >   int oldCapacity = oldTable.length;
   >   if(oldCapacity == MAXIMUM_CAPACITY){
   >     threshold = Integer.MAX_VALUE;
   >     return;
   >   }
   >   Entry[] newTable = new Entry[newCapacity];
   >   transfer(newTable);
   >   table = newTable;
   >   threshold = (int)(newCapacity * loadFactor)
   > }
   > 
   > //而这段代码中又调用了transfer()方法，而这个方法实现的机制就是将每个链表转化到新链表，并且链表中的位置发生反转，而这在多线程情况下是很容易造成链表回路，从而发生get()死循环，我们看一下他的源代码
   > 
   > void transfer(Entry[] newTable){
   >   Entry[] src = table;
   >   int newCapacity = newTable.length;
   >   for(int j =0;j<src.length;j++){
   >     Entry<K,V> e = src[j];
   >     if(e != null){
   >       src[j] = null;
   >       do{
   >         Entry<K,V> next = e.next;
   >         int i = indexFor(e.hash,newCapacity);
   >         e.next = newTable[i];
   >         newTable[i] = e;
   >         e = next;
   >       }while(e !=null);
   >     }
   >   }
   > }
   > 
   > //假如有两个线程P1、P2，以及链表 a=》b=》null
   > 1、P1先执行，执行完"Entry<K,V> next = e.next;"代码后发生阻塞，或者其他情况不再执行下去，此时e=a，next=b
   > 2、而P2已经执行完整段代码，于是当前的新链表newTable[i]为b=》a=》null
   > 3、P1又继续执行"Entry<K,V> next = e.next;"之后的代码，则执行完"e=next;"后，newTable[i]为a《=》b，则造成回路，while(e!=null)一直死循环
   > ```

   6.5 HashMap的扩容？

   > 答：
   >
   > 1.7 中整个扩容过程就是一个取出数组元素（实际数组索引位置上的每个元素是每个独立单向链表的头部，也就是发生 Hash 冲突后最后放入的冲突元素）然后遍历以该元素为头的单向链表元素，依据每个被遍历元素的 hash 值计算其在新数组中的下标然后进行交换（即原来 hash 冲突的单向链表尾部变成了扩容后单向链表的头部）。
   >
   > 而在JDK 1.8 中 HashMap 由于扩容数组的长度是 2 倍关系，所以对于假设初始 tableSize = 4 要扩容到 8 来说就是 0100 到 1000 的变化（左移一位就是 2 倍），在扩容中只用判断原来的 hash 值与左移动的一位（newtable 的值）按位与操作是 0 或 1 就行，0 的话索引就不变，1 的话索引变成原索引加上扩容前数组
   >
   > 因为hash 值本来就是随机性的，所以 hash 按位与上 newTable 得到的 0（扩容前的索引位置）和 1（扩容前索引位置加上扩容前数组长度的数值索引处）就是随机的，所以扩容的过程就能把之前哈希冲突的元素再随机的分布到不同的索引去，这算是 JDK1.8 的一个优化点。
   >
   > 此外，在JDK1.7 中扩容操作时，哈希冲突的数组索引处的旧链表元素扩容到新数组时，如果扩容后索引位置在新数组的索引位置与原数组中索引位置相同，则链表元素会发生倒置（即如上面图1，原来链表头扩容后变为尾巴）；而在 JDK1.8 中不会出现链表倒置现象。
   >
   > 其次，由于JDK1.7 中发生哈希冲突时仅仅采用了链表结构存储冲突元素，所以扩容时仅仅是重新计算其存储位置而已，而 JDK1.8 中为了性能在同一索引处发生哈希冲突到一定程度时链表结构会转换为红黑数结构存储冲突元素，故在扩容时如果当前索引中元素结构是红黑树且元素个数小于链表还原阈值（哈希冲突程度常量）时就会把树形结构缩小或直接还原为链表结构（其实现就是上面代码片段中的 split() 方法）

   6.6 HashMap在高并发下如果没有处理线程安全会有什么隐患，具体表现是什么？

   > 答：
   >
   > 在高并发情况下有可能会形成循环链表，具体表现为CPU的使用率达到100%
   >
   > 还有一个中可能是因为如果两个线程同时进行对一个节点记性put的时候，可能会出现最后一个put操作会覆盖第一个put的数据。

   6.7 ArrayList是如何扩容的（默认数组大小是10）？

   > 答：
   >
   > 首先当你执行add（）方法的时候，会先调用这个方法ensureCapacityInternal()来确保数组的容量够用，然后会继续在这个方法中调用ensureExplicitCapacity（alculateCapacity(elementData, minCapacity)）中的alculateCapacity(elementData, minCapacity)方法来进行比较出是ArrayList中的默认容量和自己初始化的容量那个更大，返回最大的那个作为最后数组的容量。
   >
   > 把上一个获得的最终数组最大的容量传给ensureExplicitCapacity（上一步中最大的值max），然后进行判断如果这个最大的值大于数组中的元素的长度的话，就说明数组的容量不够存储这个数组的元素的大小，然后进行扩容grow（）。
   >
   > 在grow（）方法中，先进行对之前的数组容量进行1.5倍扩容，然后判断如果扩容1.5倍后的大小仍然小于之前数组最终那次初始化的容量大小时，说明按此初始化的数组容量大小仍然可以满足，直接把扩容后的数组大小还是初始化的那个，依然不变。
   >
   > 如果扩容后的新数组大小大于Integer-8的值的话，反正不能超过Integer的范围，最后直接调用Arrays.copyOf（）方法进行复制数组。

   6.8 JDK1.7 和JDK1.8 的ConcurrentHashMap的区别？

   > 答：结构上：JDK1.7中的时候ConcurrentHashMap采用了数组+Segment+分段锁的方式实现。而1.8使用的是数组+CAS+红黑树/链表来进行实现的。
   >
   > 保证线程安全的锁机制上：JDK1.7采用segment的分段锁机制实现线程安全，其中segment继承自ReentrantLock。JDK1.8采用CAS+Synchronized保证线程安全。
   >
   > 锁的粒度：原来是对需要进行数据操作的Segment加锁，现调整为对每个数组元素加锁（Node）。
   >
   > 链表转化为红黑树:定位结点的hash算法简化会带来弊端,Hash冲突加剧,因此在链表节点数量大于8时，会将链表转化为红黑树进行存储。
   >
   > 查询时间复杂度：从原来的遍历链表O(n)，变成遍历红黑树O(logN)。

   6.9 HashSet和TreeSet的区别？

   > 答：HashSet底层其实相当于是包了一层HashMap，但是又不同于HashMap，不仅不提供get（）方法，因为它是基于hash表的这样一种数据结构，在查询和删除快，添加比较慢，因为它是根据存进来的对象的hashcode来进行定位数据，所以如果是添加对象的话，一般建议需要进行重写hashCode（）和equals()方法。
   >
   > 第一个他的特点就是存储的数据都是无序的。
   >
   > 第二个就是他存储的数据不能重复，因为它是靠对象的hashCode（）方法和equals（）方法来进行区分重复数据的。
   >
   > 而TreeSet的底层其实是包了一层TreeMap的，他之所以能进行对数据的排序是因为他的底层是使用了二叉树（这样的话，当他的数据越多树的高度越高效率就越低）
   >
   > TreeSet的特点就是他可以进行排序数据，因为他是基于Comparable接口来进行区分重复的数据的，它是基于树的数据结构的，所以他的查询删除、containsValue（）的时间复杂度都是O（logN）

   6.10 HashMap和HashTable的区别？

   > 答：Hashtable是java一开始发布时就提供的键值映射的数据结构，而HashMap产生于JDK1.2。虽然Hashtable比HashMap出现的早一些，但是现在Hashtable基本上已经被弃用了。而HashMap已经成为应用最为广泛的一种数据类型了。造成这样的原因一方面是因为Hashtable是线程安全的，效率比较低。也可能是Hashtable开始设计的时候没有遵循驼峰命名法（手动笑哭）。
   >
   > 1、父类不同：
   >
   > HashMap是继承自AbstractMap类，而HashTable是继承自Dictionary（已被废弃，详情看源代码）。不过它们都实现了同时实现了map、Cloneable（可复制）、Serializable（可序列化）这三个接口。
   >
   > Hashtable比HashMap多提供了elments() 和contains() 两个方法。
   >
   > elments() 方法继承自Hashtable的父类Dictionnary。elements() 方法用于返回此Hashtable中的value的枚举。
   >
   > contains()方法判断该Hashtable是否包含传入的value。它的作用与containsValue()一致。事实上，contansValue() 就只是调用了一下contains() 方法。
   >
   > 2、null值问题
   >
   > Hashtable既不支持Null key也不支持Null value。Hashtable的put()方法的注释中有说明 。
   >
   > HashMap中，null可以作为键，这样的键只有一个；可以有一个或多个键所对应的值为null。当get()方法返回null值时，可能是 HashMap中没有该键，也可能使该键所对应的值为null。因此，在HashMap中不能由get()方法来判断HashMap中是否存在某个键， 而应该用containsKey()方法来判断。
   >
   > 3、线程安全性
   >
   > Hashtable是线程安全的，它的每个方法中都加入了Synchronize方法。在多线程并发的环境下，可以直接使用Hashtable，不需要自己为它的方法实现同步
   >
   > HashMap不是线程安全的，在多线程并发的环境下，可能会产生死锁等问题。具体的原因在下一篇文章中会详细进行分析。使用HashMap时就必须要自己增加同步处理，
   >
   > 虽然HashMap不是线程安全的，但是它的效率会比Hashtable要好很多。这样设计是合理的。在我们的日常使用当中，大部分时间是单线程操作的。HashMap把这部分操作解放出来了。当需要多线程操作的时候可以使用线程安全的ConcurrentHashMap。ConcurrentHashMap虽然也是线程安全的，但是它的效率比Hashtable要高好多倍。因为ConcurrentHashMap使用了分段锁，并不对整个数据进行锁定。
   >
   > tip：HashMap是JDk1.2之后有的，而在JDK1.5中，伟大的Doug Lea给我们带来了concurrent包，从此Map也有安全的了。也就就是有了ConcurrentHashMap（关于这个的理解下次有机会再写，或自行百度）
   >
   > 4、遍历方式不同
   >
   > Hashtable、HashMap都使用了Iterator。而由于历史原因，Hashtable还使用了Enumeration的方式 。
   >
   > HashMap的Iterator是fail-fast迭代器。当有其它线程改变了HashMap的结构（增加，删除，修改元素），将会抛出ConcurrentModificationException。不过，通过Iterator的remove()方法移除元素则不会抛出ConcurrentModificationException异常。但这并不是一个一定发生的行为，要看JVM。
   >
   > JDK8之前的版本中，Hashtable是没有fast-fail机制的。在JDK8及以后的版本中 ，Hashtable也是使用fast-fail的。（此处可以去看一下1.5和1.8JDK源码的对比）
   >
   > 5、初始容量不同
   >
   > Hashtable的初始长度是11，之后每次扩充容量变为之前的2n+1（n为上一次的长度）
   >
   > 而HashMap的初始长度为16，之后每次扩充变为原来的两倍
   >
   > 创建时，如果给定了容量初始值，那么Hashtable会直接使用你给定的大小，而HashMap会将其扩充为2的幂次方大小。
   >
   > 6、计算哈希值的方法不同
   >
   > 为了得到元素的位置，首先需要根据元素的KEY计算出一个hash值，然后再用这个hash值来计算得到最终的位置
   >
   > Hashtable直接使用对象的hashCode。hashCode是JDK根据对象的地址或者字符串或者数字算出来的int类型的数值。然后再使用除留余数发来获得最终的位置。 然而除法运算是非常耗费时间的。效率很低
   >
   > HashMap为了提高计算效率，将哈希表的大小固定为了2的幂，这样在取模预算时，不需要做除法，只需要做位运算。位运算比除法的效率要高很多。

   6.11 HashMap和ConcurrentHashMap在线程安全上有何区别？如何实现？

   > 答：1：hashMap与是采用链式hash表实现。也就是HashMap表里面有一个Entry[]数组，当一个键值对加入该数据的时候，会通过key的hashcode去计算存在那一个数组位置，当通过不同的hashCode计算出出现相同的entry数组位置的时候，则会在该位置以链表的形式存储。
   >
   > 2：hashMap存在一个问题，就是会当hash表的容量超过设定的容量的时候，就会出现rehash，此时会创建一个新的entry数组，然后将原来的entry[]数组中的数据复制到新的数组中，但是复制的时候就会重新根据key的hashCode来计算存入位置，数据量大的时候比较耗费资源，所以我们在能预估hashMap大小的是时候尽量在初始化的时候给适当的值。（hashMap每次扩容为原来的两倍）
   >
   > 3：hash表解决冲突的做法：1：保证每一扩容都为2的n次方（int capacity = 1; while (capacity < initialCapacity) capacity <<= 1; ），从这儿我们可以看出，我们不是我们给的初值是多少，map的容量就是多少，而已2的n次方，然后跟我们给的初值很相近（具体原因可以根据数学上的计算的来的）。2：负载因子取一个平衡值，负载因子也是影响冲突的一个因素，当负载因子越大，则数组利用率越高，但是对应查询的时间复杂度增加（因为变密集了吗），当负载在因子越小，则越稀疏，则越不容易冲突。
   >
   > 4:hashMap初始容量为16，负载因子默认为0.75（平衡值）；扩容阈值=原容量*负载因子。16*0.75=12，也就是存入了12个就扩容，扩容以后是2*16=32；
   >
   > 5：ConcurrentHashMap采用分段锁的概念，将一个数组分成一个个小的HashTable,因此就是提高类并发编程类Map的效率。线程只是对一个段里面HashTable加锁，而不是整个map对象加锁。
   >
   > 6：具体的做法就是有一个segmetn[]数组，该数组中segment对象就相当于一个HashMap,当一个键值对put进来的时候，首先通过key值计算该对象存在哪一个segment中，当定到哪一个段以后，再在段中计算hash值，然后存入hashEntry[]数组中的对应位置，接下来就和hashMap差不多了。这样的话我们只要锁定一个段就可以了，而不用锁定整个segment数组，如过一个线程操作其中的一个段，另个一线操作的另一个段，那么他们就不存在竞争的现象。

   6.12 TreeMap、HashMap、LinkedHashMap的区别？

   > 答：
   >
   > 1：TreeMap采用的是红黑树实现的，他的查询时间复杂度是o（logn），而LinkedHashMap遍历采用的哈希表加双向循环列表实现的，通过key查询value时间复杂度是o（1），LinkedHashMap就是解决TreeMap的不足的；
   >
   > 2：LinkedHashMap可以通过设置accessOrder来确定是否使用LRU（Least Recently Used）算法，如果accessOrder=true，则表示使用lru，如果是false，则不用，遍历循序和插入循序一致。
   >
   > 3：LinkedHashMap实现原理：具体做法是在存入第一entry的时候，将其赋值给head，当第二来entry来的时候，先和head建立起双向循环链表的关系，然后在存入entry[]数组结构中。以后没来一个就先和之前的已经建立好的循环链表中加入自己，然后按照hashMap的规则存到数组当中。这样查找和遍历就相互分开了。

7. 设计模式

   7.1 单例模式的线程安全性

8. 分布式

   8.1 分布式事务与分布式锁？（扣款不要出现负数）

   > 答:
   >
   > 数据库实现分布式锁
   >
   > 利用DB来实现分布式锁，有两种方案。两种方案各有好坏，但是总体效果都不是很好。但是实现还是比较简单的。
   >
   > 利用主键唯一规则：
   > 我们知道数据库是有唯一主键规则的，主键不能重复，对于重复的主键会抛出主键冲突异常。
   > 了解JDK reentrantlock的人都知道，reentrantlock是利用了OS的CAS特性实现的锁。主要是维护一个全局的状态，每次竞争锁都会CAS修改锁的状态，修改成功之后就占用了锁，失败的加入到同步队列中，等待唤醒。
   > 其实这和分布式锁实现方案基本是一致的，首先我们利用主键唯一规则，在争抢锁的时候向DB中写一条记录，这条记录主要包含锁的id、当前占用锁的线程名、重入的次数和创建时间等，如果插入成功表示当前线程获取到了锁，如果插入失败那么证明锁被其他人占用，等待一会儿继续争抢，直到争抢到或者超时为止。
   >
   > ```java
   > import java.sql.Connection;
   > import java.sql.DriverManager;
   > import java.sql.PreparedStatement;
   > import java.sql.SQLException;
   > import java.util.concurrent.CountDownLatch;
   > import java.util.concurrent.TimeUnit;
   > 
   > /**
   >  * 利用mysql实现可重入分布式锁
   >  */
   > public class MysqlprimaryLock {
   >     private static Connection connection;
   >     static {
   >         try {
   >             Class.forName("com.mysql.jdbc.Driver");
   >         } catch (ClassNotFoundException e) {
   >             e.printStackTrace();
   >         }
   >         String url = "jdbc:mysql://10.0.0.212:3308/dbwww_lock?user=lock_admin&password=lock123";
   >         try {
   >             connection = DriverManager.getConnection(url);
   >         } catch (SQLException e) {
   >             e.printStackTrace();
   >         }
   >     }
   > 
   >     /**
   >      * 加锁
   >      * @param lockID
   >      */
   >     public void lock(String lockID) {
   >         acquire(lockID);
   >     }
   > 
   >     /**
   >      * 获取锁
   >      * @param lockID
   >      * @return
   >      */
   >     public boolean acquire(String lockID) {
   >         String sql = "insert into test_lock('id','count','thName','addtime') VALUES (?,?,?,?)";
   >         while (true) {
   >             try {
   >                 PreparedStatement statement = connection.prepareStatement(sql);
   >                 statement.setString(1, lockID);
   >                 statement.setInt(2, 1);
   >                 statement.setLong(1, System.currentTimeMillis());
   >                 boolean ifsucess = statement.execute();//如果成功，那么就是获取到了锁
   >                 if (ifsucess)
   >                     return true;
   >             } catch (SQLException e) {
   >                 e.printStackTrace();
   >             }
   >             try {
   >                 Thread.sleep(1000);
   >             } catch (InterruptedException e) {
   >                 e.printStackTrace();
   >             }
   >             continue;
   >         }
   >     }
   > 
   >     /**
   >      * 超时获取锁
   >      * @param lockID
   >      * @param timeOuts
   >      * @return
   >      * @throws InterruptedException
   >      */
   >     public boolean acquire(String lockID, long timeOuts) throws InterruptedException {
   > 
   >         String sql = "insert into test_lock('id','count','thName','addtime') VALUES (?,?,?,?)";
   >         long futureTime = System.currentTimeMillis() + timeOuts;
   >         long ranmain = timeOuts;
   >         long timerange = 500;
   >         while (true) {
   >             CountDownLatch latch = new CountDownLatch(1);
   >             try {
   >                 PreparedStatement statement = connection.prepareStatement(sql);
   >                 statement.setString(1, lockID);
   >                 statement.setInt(2, 1);
   >                 statement.setLong(1, System.currentTimeMillis());
   >                 boolean ifsucess = statement.execute();//如果成功，那么就是获取到了锁
   >                 if (ifsucess)
   >                     return true;
   >             } catch (SQLException e) {
   >                 e.printStackTrace();
   >             }
   >             latch.await(timerange, TimeUnit.MILLISECONDS);
   >             ranmain = futureTime - System.currentTimeMillis();
   >             if (ranmain <= 0)
   >                 break;
   >             if (ranmain < timerange) {
   >                 timerange = ranmain;
   >             }
   >             continue;
   >         }
   >         return false;
   > 
   >     }
   > 
   >     /**
   >      * 释放锁
   >      * @param lockID
   >      * @return
   >      * @throws SQLException
   >      */
   >     public boolean unlock(String lockID) throws SQLException {
   >         String sql = "DELETE  from test_lock where id = ?";
   >         PreparedStatement statement = connection.prepareStatement(sql);
   >         statement.setString(1, lockID);
   >         boolean ifsucess = statement.execute();
   >         if (ifsucess)
   >             return true;
   >         return false;
   > 
   >     }
   > 
   > }
   > //这里是利用主键冲突规则，加入了id','count','thName','addtime'，count主要是为了重入计数，thName为了判断占用锁的线程，addtime是记录占用时间。上面代码没有实现重入的逻辑。
   > //重入主要实现思路是，在每次获取锁之前去取当前锁的信息，如果锁的线程是当前线程，那么更新锁的count+1，并且执行锁之后的逻辑。如果不是当前锁，那么进行重试。释放的时候也要进行count-1，最后减到0时，删除锁标识释放锁。
   > //优点：实现简单
   > //缺点：没有超时保护机制，mysql存在单点，并发量大的时候请求量太大、没有线程唤醒机制，用异常去控制逻辑多少优点恶心。
   > //对于超时保护：如果可能，可以采用定时任务去扫描超过一定阈值的锁，并删除。但是也会存在，锁住的任务执行时间很长，删除锁会导致并发问题。所以需要对超时时间有一个很好的预估。
   > //对于单点问题：有条件可以搞一个主从，但是为了一个锁来搞一个主从是不是优点浪费？同时主从切换的时候系统不可用，这也是一个问题。
   > //并发量大的时候请求量太大：因为这种实现方式是没有锁的唤醒机制的，不像reentrantlock在同步队列中的节点，可以通过唤醒来避免多次的循环请求。但是分布式环境数据库这种锁的实现是不能做到唤醒的。所以只能将获取锁的时间间隔调高，避免死循环给系统和DB带来的巨大压力。这样也牺牲了系统的吞吐量，因为总会有一定的间隔锁是空闲的。
   > //用异常去控制逻辑多少优点恶心：就不说了，每次失败都抛异常.....
   > ```
   >
   > 
   >
   > 利用Mysql行锁的特性：
   >
   > Mysql是有表锁、页锁和行锁的机制的，可以利用这个机制来实现锁。这里尽量使用行锁，它的吞吐量是最高的。
   >
   > ```java
   >  /**
   >      * 超时获取锁
   >      * @param lockID
   >      * @param timeOuts
   >      * @return
   >      * @throws InterruptedException
   >      */
   >     public boolean acquireByUpdate(String lockID, long timeOuts) throws InterruptedException, SQLException {
   > 
   >         String sql = "SELECT id from test_lock where id = ? for UPDATE ";
   >         long futureTime = System.currentTimeMillis() + timeOuts;
   >         long ranmain = timeOuts;
   >         long timerange = 500;
   >         connection.setAutoCommit(false);
   >         while (true) {
   >             CountDownLatch latch = new CountDownLatch(1);
   >             try {
   >                 PreparedStatement statement = connection.prepareStatement(sql);
   >                 statement.setString(1, lockID);
   >                 statement.setInt(2, 1);
   >                 statement.setLong(1, System.currentTimeMillis());
   >                 boolean ifsucess = statement.execute();//如果成功，那么就是获取到了锁
   >                 if (ifsucess)
   >                     return true;
   >             } catch (SQLException e) {
   >                 e.printStackTrace();
   >             }
   >             latch.await(timerange, TimeUnit.MILLISECONDS);
   >             ranmain = futureTime - System.currentTimeMillis();
   >             if (ranmain <= 0)
   >                 break;
   >             if (ranmain < timerange) {
   >                 timerange = ranmain;
   >             }
   >             continue;
   >         }
   >         return false;
   > 
   >     }
   > 
   > 
   >     /**
   >      * 释放锁
   >      * @param lockID
   >      * @return
   >      * @throws SQLException
   >      */
   >     public void unlockforUpdtate(String lockID) throws SQLException {
   >         connection.commit();
   >     }
   > 
   > //利用for update加显式的行锁，这样就能利用这个行级的排他锁来实现分布式锁了，同时unlock的时候只要释放commit这个事务，就能达到释放锁的目的。
   > //优点：实现简单
   > //缺点：连接池爆满和事务超时的问题单点的问题，单点问题，行锁升级为表锁的问题，并发量大的时候请求量太大、没有线程唤醒机制。
   > //连接池爆满和事务超时的问题单点的问题：利用事务进行加锁的时候，query需要占用数据库连接，在行锁的时候连接不释放，这就会导致连接池爆满。同时由于事务是有超时时间的，过了超时时间自动回滚，会导致锁的释放，这个超时时间要把控好。
   > //对于单点问题：同上。
   > //并发量大的时候请求量太大：同上。
   > //行锁升级为表锁的问题：Mysql行锁默认需要走索引，如果不走索引会导致锁表，如果可以，在sql中可以强制指定索引。
   > ```
   >
   > ##### 缓存分布式锁####
   >
   > 缓存实现分布式锁还是比较常见的，因为缓存比较轻量，并且缓存的响应快、吞吐高。最重要的是还有自动失效的机制来保证锁一定能释放。
   >
   > 缓存的分布式锁主要通过Redis实现，当然其他的缓存也是可以的。关于缓存有两种实现吧：
   >
   > 基于SetNX实现：
   > setNX是Redis提供的一个原子操作，如果指定key存在，那么setNX失败，如果不存在会进行Set操作并返回成功。我们可以利用这个来实现一个分布式的锁，主要思路就是，set成功表示获取锁，set失败表示获取失败，失败后需要重试。
   >
   > ```java
   > import redis.clients.jedis.Jedis;
   > import java.util.concurrent.*;
   > import java.util.concurrent.atomic.AtomicInteger;
   > 
   > /**
   >  * Redis分布式锁
   >  */
   > public class RedisLockTest {
   > 
   >     private Jedis jedisCli = new Jedis("localhost",6381);
   > 
   >     private int expireTime = 1;
   > 
   >     /**
   >      * 获取锁
   >      * @param lockID
   >      * @return
   >      */
   >     public boolean lock(String lockID){
   >         while(true){
   >             long returnFlag = jedisCli.setnx(lockID,"1");
   >             if (returnFlag == 1){
   >                 System.out.println(Thread.currentThread().getName() + " get lock....");
   >                 return true;
   >             }
   >             System.out.println(Thread.currentThread().getName() + " is trying lock....");
   >             try {
   >                 Thread.sleep(2000);
   >             } catch (InterruptedException e) {
   >                 e.printStackTrace();
   >                 return false;
   >             }
   >         }
   >     }
   > 
   >     /**
   >      * 超时获取锁
   >      * @param lockID
   >      * @param timeOuts
   >      * @return
   >      */
   >     public boolean lock(String lockID,long timeOuts){
   >         long current = System.currentTimeMillis();
   >         long future = current + timeOuts;
   >         long timeStep = 500;
   >         CountDownLatch latch = new CountDownLatch(1);
   >         while(future > current){
   >             long returnFlag = jedisCli.setnx(lockID,"1");
   >             if (returnFlag == 1){
   >                 System.out.println(Thread.currentThread().getName() + " get lock....");
   >                 jedisCli.expire(lockID,expireTime);
   >                 return true;
   >             }
   >             System.out.println(Thread.currentThread().getName() + " is trying lock....");
   >             try {
   >                 latch.await(timeStep, TimeUnit.MILLISECONDS);
   >             } catch (InterruptedException e) {
   >                 e.printStackTrace();
   >             }
   >             current = current + timeStep;
   >         }
   >         return false;
   >     }
   > 
   >     public void unlock(String lockId){
   >         long flag = jedisCli.del(lockId);
   >         if (flag>0){
   >             System.out.println(Thread.currentThread().getName() + " release lock....");
   >         }else {
   >             System.out.println(Thread.currentThread().getName() + " release lock fail....");
   >         }
   >     }
   > 
   >     /**
   >      * 线程工厂,命名线程
   >      */
   >     public static class MyThreadFactory implements ThreadFactory{
   >         public static AtomicInteger count = new AtomicInteger();
   >         @Override
   >         public Thread newThread(Runnable r) {
   >             count.getAndIncrement();
   >             Thread thread = new Thread(r);
   >             thread.setName("Thread-lock-test "+count);
   >             return thread;
   >         }
   >     }
   > 
   >     public static void main(String args[]){
   >         final String lockID = "test1";
   >         Runnable task = () ->{
   >             RedisLockTest testCli = new RedisLockTest();
   >             testCli.lock(lockID);
   >             try {
   >                 Thread.sleep(2000);
   >             } catch (InterruptedException e) {
   >                 e.printStackTrace();
   >             }
   >             testCli.unlock(lockID);
   >         };
   > 
   >         MyThreadFactory factory = new MyThreadFactory();
   >         ExecutorService services = Executors.newFixedThreadPool(10);
   >         for (int i = 0;i<3;i++)
   >             services.execute(factory.newThread(task));
   >     }
   > 
   > }
   > //可以看到，几个线程很好的进行了同步。
   > //这种方式也是有优点和缺点：
   > //优点：实现简单，吞吐量十分客观，对于高并发情况应付自如，自带超时保护，对于网络抖动的情况也可以利用超时删除策略保证不会阻塞所有流程。
   > //缺点：单点问题、没有线程唤醒机制、网络抖动可能会引起锁删除失败。
   > //对单点问题：因为redis一般都是单实例使用，那么对于单点问题，可以做一个主从。当然主从切换的时候也是不可用的，因为主从同步是异步的，可能会并发问题。如果对于主从还是不能保证可靠性的话，可以上Redis集群，对于Redis集群，因为使用了类一致性Hash算法，虽然不能避免节点下线的并发问题(当前的任务没有执行完，其他任务就开始执行)，但是能保证Redis是可用的。
   > //对于线程唤醒机制：分布式锁大多都是这样轮训获取锁的，所以控制住你的重试频率，也不会导致负载特别高的。可能就是吞吐量低点而已。
   > //对于锁删除失败：分布式锁基本都有这个问题，可以对key设置失效时间。这个超时时间需要把控好，过大那么系统吞吐量低，很容易导致超时。如果过小那么会有并发问题，部分耗时时间比较长的任务就要遭殃了。
   > ```

   8.2 分布式session设置？

   8.3 分布式session一致性？

   8.4 分布式接口的幂等性（不能重复扣款）？

9. 应用场景

   9.1 线上的服务器监控指标，你认为哪些指标是需要关注的？为什么？

   9.2 设计一个秒杀系统？（事务、逻辑调整、数据库并发、mybatis调用存储过程）

   9.3 JVM相关的分析工具用过哪些？说说具体的性能调优步骤？

10. 缓存

  10.1 Redis如何处理key冲突？

  > 答：
  >
  > 第一种方案：分布式锁
  >
  > 1.整体技术方案
  >
  > 这种情况，主要是准备一个分布式锁，大家去抢锁，抢到锁就做set操作。
  >
  > 2.为什么是分布式锁
  >
  > 因为传统的加锁的做法（如java的synchronized和Lock）这里没用，只适合单点。因为这是分布式环境，需要的是分布式锁。
  >
  > 当然，分布式锁可以基于很多种方式实现，比如zookeeper、redis等，不管哪种方式实现，基本原理是不变的：用一个状态值表示锁，对锁的占用和释放通过状态值来标识。
  >
  > 3.分布式锁的要求
  >
  >  互斥性：在任意一个时刻，只有一个客户端持有锁。
  >
  >  无死锁：即便持有锁的客户端崩溃或者其他意外事件，锁仍然可以被获取。
  >
  >  容错：只要大部分Redis节点都活着，客户端就可以获取和释放锁
  >
  > 4.分布式锁的实现方式
  >
  >  数据库
  >
  >  Memcached（add命令）
  >
  >  Redis（setnx命令）
  >
  >  Zookeeper（临时节点）
  >
  > 
  >
  > 第二种方案：利用消息队列
  >
  > 在并发量过大的情况下,可以通过消息中间件进行处理,把并行读写进行串行化。
  >
  > 把Redis.set操作放在队列中使其串行化,必须的一个一个执行。
  >
  > 这种方式在一些高并发的场景中算是一种通用的解决方案。

  10.2 如何保存数据库和redis缓存一致？

  10.3 缓存的穿透和雪崩，解决办法？

  > 答：
  >
  > 缓存穿透，缓存击穿，缓存雪崩解决方案分析
  >
  > 缓存穿透
  > 缓存穿透是指查询一个一定不存在的数据，由于缓存是不命中时被动写的，并且出于容错考虑，如果从存储层查不到数据则不写入缓存，这将导致这个不存在的数据每次请求都要到存储层去查询，失去了缓存的意义。在流量大时，可能DB就挂掉了，要是有人利用不存在的key频繁攻击我们的应用，这就是漏洞。
  >
  > 解决方案
  > 有很多种方法可以有效地解决缓存穿透问题，最常见的则是采用布隆过滤器，将所有可能存在的数据哈希到一个足够大的bitmap中，一个一定不存在的数据会被 这个bitmap拦截掉，从而避免了对底层存储系统的查询压力。另外也有一个更为简单粗暴的方法（我们采用的就是这种），如果一个查询返回的数据为空（不管是数 据不存在，还是系统故障），我们仍然把这个空结果进行缓存，但它的过期时间会很短，最长不超过五分钟。
  >
  > 补充:Bloom filter
  >
  > 适用范围：可以用来实现数据字典，进行数据的判重，或者集合求交集
  >
  > 基本原理及要点：对于原理来说很简单，位数组+k个独立hash函数。将hash函数对应的值的位数组置1，查找时如果发现所有hash函数对应位都是1说明存在，很明显这个过程并不保证查找的结果是100%正确的。同时也不支持删除一个已经插入的关键字，因为该关键字对应的位会牵动到其他的关键字。所以一个简单的改进就是counting Bloom filter，用一个counter数组代替位数组，就可以支持删除了。添加时增加计数器，删除时减少计数器。
  >
  > 缓存空对象. 将 null 变成一个值.
  >
  > 也可以采用一个更为简单粗暴的方法，如果一个查询返回的数据为空（不管是数据不存在，还是系统故障），我们仍然把这个空结果进行缓存，但它的过期时间会很短，最长不超过五分钟。
  >
  > 缓存空对象会有两个问题：
  >
  > 第一，空值做了缓存，意味着缓存层中存了更多的键，需要更多的内存空间( 如果是攻击，问题更严重 )，比较有效的方法是针对这类数据设置一个较短的过期时间，让其自动剔除。
  >
  > 第二，缓存层和存储层的数据会有一段时间窗口的不一致，可能会对业务有一定影响。例如过期时间设置为5分钟，如果此时存储层添加了这个数据，那此段时间就会出现缓存层和存储层数据的不一致，此时可以利用消息系统或者其他方式清除掉缓存层中的空对象。

  > 缓存雪崩
  > 缓存雪崩是指在我们设置缓存时采用了相同的过期时间，导致缓存在某一时刻同时失效，请求全部转发到DB，DB瞬时压力过重雪崩。
  >
  > 解决方案
  > 缓存失效时的雪崩效应对底层系统的冲击非常可怕。大多数系统设计者考虑用加锁或者队列的方式保证缓存的单线 程（进程）写，从而避免失效时大量的并发请求落到底层存储系统上。这里分享一个简单方案就时讲缓存失效时间分散开，比如我们可以在原有的失效时间基础上增加一个随机值，比如1-5分钟随机，这样每一个缓存的过期时间的重复率就会降低，就很难引发集体失效的事件。
  >
  > 加锁排队. 限流-- 限流算法. 1.计数 2.滑动窗口 3.  令牌桶Token Bucket 4.漏桶 leaky bucket [1]在缓存失效后，通过加锁或者队列来控制读数据库写缓存的线程数量。比如对某个key只允许一个线程查询数据和写缓存，其他线程等待。
  >
  > 业界比较常用的做法，是使用mutex。简单地来说，就是在缓存失效的时候（判断拿出来的值为空），不是立即去load db，而是先使用缓存工具的某些带成功操作返回值的操作（比如Redis的SETNX或者Memcache的ADD）去set一个mutex key，当操作返回成功时，再进行load db的操作并回设缓存；否则，就重试整个get缓存的方法。
  >
  > SETNX，是「SET if Not eXists」的缩写，也就是只有不存在的时候才设置，可以利用它来实现锁的效果。
  >
  > 2.数据预热
  >
  > 可以通过缓存reload机制，预先去更新缓存，再即将发生大并发访问前手动触发加载缓存不同的key，设置不同的过期时间，让缓存失效的时间点尽量均匀
  >
  > 3.做二级缓存，或者双缓存策略。
  >
  > A1为原始缓存，A2为拷贝缓存，A1失效时，可以访问A2，A1缓存失效时间设置为短期，A2设置为长期
  >
  > 4.缓存永远不过期
  >
  > 这里的“永远不过期”包含两层意思：
  >
  > (1) 从缓存上看，确实没有设置过期时间，这就保证了，不会出现热点key过期问题，也就是“物理”不过期。
  >
  > (2) 从功能上看，如果不过期，那不就成静态的了吗？所以我们把过期时间存在key对应的value里，如果发现要过期了，通过一个后台的异步线程进行缓存的构建，也就是“逻辑”过期.
  >
  > 从实战看，这种方法对于性能非常友好，唯一不足的就是构建缓存时候，其余线程(非构建缓存的线程)可能访问的是老数据，但是对于一般的互联网功能来说这个还是可以忍受。
  >
  > 

  > 缓存击穿
  > 对于一些设置了过期时间的key，如果这些key可能会在某些时间点被超高并发地访问，是一种非常“热点”的数据。这个时候，需要考虑一个问题：缓存被“击穿”的问题，这个和缓存雪崩的区别在于这里针对某一key缓存，前者则是很多key。
  >
  > 缓存在某个时间点过期的时候，恰好在这个时间点对这个Key有大量的并发请求过来，这些请求发现缓存过期一般都会从后端DB加载数据并回设到缓存，这个时候大并发的请求可能会瞬间把后端DB压垮。
  >
  > 解决方案
  > 1.使用互斥锁(mutex key)
  > 业界比较常用的做法，是使用mutex。简单地来说，就是在缓存失效的时候（判断拿出来的值为空），不是立即去load db，而是先使用缓存工具的某些带成功操作返回值的操作（比如Redis的SETNX或者Memcache的ADD）去set一个mutex key，当操作返回成功时，再进行load db的操作并回设缓存；否则，就重试整个get缓存的方法。
  >
  > SETNX，是「SET if Not eXists」的缩写，也就是只有不存在的时候才设置，可以利用它来实现锁的效果。在redis2.6.1之前版本未实现setnx的过期时间，所以这里给出两种版本代码参考：
  >
  > ```java
  > public String get(key) {
  >       String value = redis.get(key);
  >       if (value == null) { //代表缓存值过期
  >           //设置3min的超时，防止del操作失败的时候，下次缓存过期一直不能load db
  > 		  if (redis.setnx(key_mutex, 1, 3 * 60) == 1) {  //代表设置成功
  >                value = db.get(key);
  >                       redis.set(key, value, expire_secs);
  >                       redis.del(key_mutex);
  >               } else {  //这个时候代表同时候的其他线程已经load db并回设到缓存了，这时候重试获取缓存值即可
  >                       sleep(50);
  >                       get(key);  //重试
  >               }
  >           } else {
  >               return value;      
  >           }
  >  }
  > 
  > memcache代码：
  > if (memcache.get(key) == null) {  
  >     // 3 min timeout to avoid mutex holder crash  
  >     if (memcache.add(key_mutex, 3 * 60 * 1000) == true) {  
  >         value = db.get(key);  
  >         memcache.set(key, value);  
  >         memcache.delete(key_mutex);  
  >     } else {  
  >         sleep(50);  
  >         retry();  
  >     }  
  > }
  > ```
  >
  > "提前"使用互斥锁(mutex key)：
  >
  > 在value内部设置1个超时值(timeout1), timeout1比实际的memcache timeout(timeout2)小。当从cache读取到timeout1发现它已经过期时候，马上延长timeout1并重新设置到cache。然后再从数据库加载数据并设置到cache中。伪代码如下：
  >
  > ```java
  > 
  > v = memcache.get(key);  
  > if (v == null) {  
  >     if (memcache.add(key_mutex, 3 * 60 * 1000) == true) {  
  >         value = db.get(key);  
  >         memcache.set(key, value);  
  >         memcache.delete(key_mutex);  
  >     } else {  
  >         sleep(50);  
  >         retry();  
  >     }  
  > } else {  
  >     if (v.timeout <= now()) {  
  >         if (memcache.add(key_mutex, 3 * 60 * 1000) == true) {  
  >             // extend the timeout for other threads  
  >             v.timeout += 3 * 60 * 1000;  
  >             memcache.set(key, v, KEY_TIMEOUT * 2);  
  >   
  >             // load the latest value from db  
  >             v = db.get(key);  
  >             v.timeout = KEY_TIMEOUT;  
  >             memcache.set(key, value, KEY_TIMEOUT * 2);  
  >             memcache.delete(key_mutex);  
  >         } else {  
  >             sleep(50);  
  >             retry();  
  >         }  
  >     }  
  > }
  > ```
  >
  > "永远不过期"：  
  > 这里的“永远不过期”包含两层意思：
  >
  > ```java
  > (1) 从redis上看，确实没有设置过期时间，这就保证了，不会出现热点key过期问题，也就是“物理”不过期。
  > (2) 从功能上看，如果不过期，那不就成静态的了吗？所以我们把过期时间存在key对应的value里，如果发现要过期了，通过一个后台的异步线程进行缓存的构建，也就是“逻辑”过期
  > 
  > //从实战看，这种方法对于性能非常友好，唯一不足的就是构建缓存时候，其余线程(非构建缓存的线程)可能访问的是老数据，但是对于一般的互联网功能来说这个还是可以忍受。
  > 
  > String get(final String key) {  
  >         V v = redis.get(key);  
  >         String value = v.getValue();  
  >         long timeout = v.getTimeout();  
  >         if (v.timeout <= System.currentTimeMillis()) {  
  >             // 异步更新后台异常执行  
  >             threadPool.execute(new Runnable() {  
  >                 public void run() {  
  >                     String keyMutex = "mutex:" + key;  
  >                     if (redis.setnx(keyMutex, "1")) {  
  >                         // 3 min timeout to avoid mutex holder crash  
  >                         redis.expire(keyMutex, 3 * 60);  
  >                         String dbValue = db.get(key);  
  >                         redis.set(key, dbValue);  
  >                         redis.delete(keyMutex);  
  >                     }  
  >                 }  
  >             });  
  >         }  
  >         return value;  
  > }
  > ```
  >
  > 资源保护：
  > 采用netflix的hystrix，可以做资源的隔离保护主线程池，如果把这个应用到缓存的构建也未尝不可。
  >
  > 
  >
  > 